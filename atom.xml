<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Binuxの杂货铺</title>
  
  
  <link href="https://binux.blog/atom.xml" rel="self"/>
  
  <link href="https://binux.blog/"/>
  <updated>2022-08-27T22:51:27.053Z</updated>
  <id>https://binux.blog/</id>
  
  <author>
    <name>Roy Binux</name>
    
  </author>
  
  <generator uri="https://hexo.io/">Hexo</generator>
  
  <entry>
    <title>家居自动化</title>
    <link href="https://binux.blog/2020/01/home-assistant/"/>
    <id>https://binux.blog/2020/01/home-assistant/</id>
    <published>2020-01-05T01:54:54.000Z</published>
    <updated>2022-08-27T22:51:27.053Z</updated>
    
    <content type="html"><![CDATA[<p>从 Google Assistant, Amazon Alexa, Apple Homekit 到米家，智能家居自动化已经不是什么新鲜的概念了。对于我来说，入坑的契机也非常简单：我不想下床关灯。然后随着想要自动化的场景增加，智能设备（可编程设备）就越来越多。这篇文章就根据自动场景介绍一下我现在的一些方案（本文无任何 affiliate ）。</p><h2 id="Hub"><a href="#Hub" class="headerlink" title="Hub"></a>Hub</h2><p>首先，在配置场景之前，需要选择一个 Hub —— 作为自动化中心，连接传感器和操作控制器（例如灯，插座，IR 遥控器等）。你可以选择 Google Home，Alexa，Homekit 这样大厂的方案，不过这里我还是推荐 <a href="https://www.home-assistant.io/">Home Assistant</a> 这样的开源方案：</p><ul><li>更多的<a href="https://www.home-assistant.io/integrations/">接入设备支持</a>（你甚至可以同时接入 Alexa 和 Google Assistant 的设备）</li><li>更自由的自动化配置（例如 Google Assistant 不支持延迟触发；你甚至可以写 shell 脚本）</li><li>更好的隐私保护（Home Assistant 的设备支持大多来源于逆向设备 API，能不联网就不联网）</li></ul><p>我在 Synology DS218+ 上以 docker 运行 Home Assistant。</p><p>不过无论你选择什么方案，在这之后购买传感器和控制器的时候都需要注意你的 Hub 是否支持设备接入。考虑到价格，我的设备主要是 TP-Link 的插座加上米家的传感器，我会在具体场景中详细列出。</p><h2 id="自动化场景"><a href="#自动化场景" class="headerlink" title="自动化场景"></a>自动化场景</h2><h3 id="Hey-Google-Good-Night"><a href="#Hey-Google-Good-Night" class="headerlink" title="Hey Google, Good Night"></a>Hey Google, Good Night</h3><p>首先就是我入坑的第一个场景，在床上关上家中所有的灯。我用到的设备有：</p><ul><li><a href="https://store.google.com/us/product/google_home_mini">Google Home Mini</a></li><li><a href="https://www.kasasmart.com/us/products/smart-plugs/kasa-smart-plug-energy-monitoring-hs110">TP-Link Smart Plug HS110</a></li><li><a href="https://www.kasasmart.com/us/products/smart-switches/kasa-smart-wi-fi-light-switch-hs200">TP-Link Smart Switch HS200</a></li></ul><p>由于美国的房子没有灯，对的，没·有·灯。默认的开关控制的插座不一定在我想要的位置。这时候就可以用一个 Smart Plug 接一个落地灯。而对于其他自带的例如浴室厨房灯，就通过替换 Smart Switch 控制。</p><p>设置方面也很简单，直接在 Google Home 的 Routines 中关掉所有的开关就好了。</p><h3 id="自动开关厕所灯"><a href="#自动开关厕所灯" class="headerlink" title="自动开关厕所灯"></a>自动开关厕所灯</h3><p>这也是很常见的使用场景，红外感应人进入就开灯，然后延迟关灯，用到的设备有：</p><ul><li><a href="https://www.mi.com/wangguan">米家多功能网关</a></li><li><a href="https://item.mi.com/product/5005.html">米家人体传感器</a></li><li><a href="https://www.kasasmart.com/us/products/smart-switches/kasa-smart-wi-fi-light-switch-hs200">TP-Link Smart Switch HS200</a></li></ul><p>首先跟着<a href="https://www.home-assistant.io/integrations/xiaomi_aqara/">文档</a>将米家多功能网关接入 Home Assistant，然后就可以添加 Automation 了：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token punctuation">-</span> <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">'1561354113814'</span>  <span class="token key atrule">alias</span><span class="token punctuation">:</span> Turn On Bathroom  <span class="token key atrule">trigger</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> binary_sensor.xiaomi_motion_sensor    <span class="token key atrule">platform</span><span class="token punctuation">:</span> state    <span class="token key atrule">to</span><span class="token punctuation">:</span> <span class="token string">'on'</span>  <span class="token key atrule">condition</span><span class="token punctuation">:</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>  <span class="token key atrule">action</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">data</span><span class="token punctuation">:</span>      <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> switch.bathroom_light    <span class="token key atrule">service</span><span class="token punctuation">:</span> switch.turn_on<span class="token punctuation">-</span> <span class="token key atrule">id</span><span class="token punctuation">:</span> <span class="token string">'1560102516271'</span>  <span class="token key atrule">alias</span><span class="token punctuation">:</span> Turn Off Bathroom  <span class="token key atrule">trigger</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> switch.bathroom_light    <span class="token key atrule">for</span><span class="token punctuation">:</span> <span class="token datetime number">00:10:00</span>    <span class="token key atrule">platform</span><span class="token punctuation">:</span> state    <span class="token key atrule">to</span><span class="token punctuation">:</span> <span class="token string">'on'</span>  <span class="token punctuation">-</span> <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> binary_sensor.xiaomi_motion_sensor    <span class="token key atrule">for</span><span class="token punctuation">:</span> <span class="token datetime number">00:10:00</span>    <span class="token key atrule">platform</span><span class="token punctuation">:</span> state    <span class="token key atrule">to</span><span class="token punctuation">:</span> <span class="token string">'off'</span>  <span class="token key atrule">condition</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">condition</span><span class="token punctuation">:</span> template    <span class="token key atrule">value_template</span><span class="token punctuation">:</span> '<span class="token punctuation">&#123;</span><span class="token punctuation">&#123;</span> is_state("switch.bathroom_light"<span class="token punctuation">,</span> "on") and as_timestamp(now())      <span class="token punctuation">-</span> as_timestamp(states.switch.bathroom_light.last_changed) <span class="token punctuation">></span> 600 <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span>'  <span class="token punctuation">-</span> <span class="token key atrule">condition</span><span class="token punctuation">:</span> template    <span class="token key atrule">value_template</span><span class="token punctuation">:</span> '<span class="token punctuation">&#123;</span><span class="token punctuation">&#123;</span> is_state("binary_sensor.xiaomi_motion_sensor"<span class="token punctuation">,</span> "off") and      as_timestamp(now()) <span class="token punctuation">-</span> as_timestamp(states.binary_sensor.xiaomi_motion_sensor.last_changed)      <span class="token punctuation">></span> 600 <span class="token punctuation">&#125;</span><span class="token punctuation">&#125;</span>'  <span class="token key atrule">action</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">alias</span><span class="token punctuation">:</span> <span class="token string">''</span>    <span class="token key atrule">data</span><span class="token punctuation">:</span>      <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> switch.bathroom_light    <span class="token key atrule">service</span><span class="token punctuation">:</span> switch.turn_off<span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><h3 id="进门自动开灯"><a href="#进门自动开灯" class="headerlink" title="进门自动开灯"></a>进门自动开灯</h3><p>这可以有两个方案，一个是用摄像头检测到人就开灯，或者用 Smart Lock 的开锁事件。</p><ul><li><a href="https://wyze.com/wyze-cam.html">Wyze Cam</a></li><li><a href="https://august.com/products/august-smart-lock-pro-connect">August Smart Lock Pro</a></li><li><a href="https://www.kasasmart.com/us/products/smart-switches/kasa-smart-wi-fi-light-switch-hs200">TP-Link Smart Switch HS200</a></li></ul><p>Wyze Cam 就是<a href="https://www.mi.com/xiaofang">小方智能摄像机</a> 的国外版本，你可以用<a href="https://github.com/EliasKotlyar/Xiaomi-Dafang-Hacks">开源的固件</a>。如果直接用它自带的。接入 Home Assistant 需要通过 ifttt。August Lock 就能直接支持了。</p><p>设置自动化和上面类似，condition 里面可以设置只在下班时间或者太阳落山后时才开灯。这里就贴配置了。总的来说 Smart Lock 比摄像头的方案要稳定得多，误触也少。</p><h3 id="Hey-Google-True-on-Projector"><a href="#Hey-Google-True-on-Projector" class="headerlink" title="Hey Google, True on Projector"></a>Hey Google, True on Projector</h3><p>由于经常搬家，我都是用投影代替电视的。毕竟同样的尺寸，投影机容易搬多了。然后我现在的投影机是内置音响的，所以我还有一个 soundbar。这个场景就是，当我打开投影的时候，同时打开音响，关闭客厅灯，然后 PC 的输出切换到投影上，再打开 Plex。这里面用到的是：</p><ul><li><a href="https://store.google.com/us/product/google_home_mini">Google Home Mini</a></li><li><a href="https://item.mi.com/product/9465.html">米家万能遥控器</a></li><li><a href="https://github.com/KjetilSv/Win10As">Win10As</a></li></ul><p>首先是将这几个设备接入 Home Assistant，参考 <a href="https://www.home-assistant.io/integrations/remote.xiaomi_miio/">Xiaomi IR Remote</a> 和 <a href="https://www.home-assistant.io/integrations/mqtt/">mqtt</a> 的文档就好了。</p><p>然后是控制投影的开关，当米家万能遥控器接入 Home Assistant 后，可以通过 <code>xiaomi_miio.remote_learn_command</code> 指令学习投影遥控的开关机代码，然后在 Home Assistant 中建立一个虚拟开关：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">remote</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">platform</span><span class="token punctuation">:</span> xiaomi_miio    <span class="token key atrule">host</span><span class="token punctuation">:</span> 192.168.1.104    <span class="token key atrule">token</span><span class="token punctuation">:</span> dxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxb    <span class="token key atrule">commands</span><span class="token punctuation">:</span>      <span class="token key atrule">project_on</span><span class="token punctuation">:</span>        <span class="token key atrule">command</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> raw<span class="token punctuation">:</span>nMwmkwlk0mkxmEsms4mEsmM2m0wlk2AMKYzYBYgCDmoDLTUA85gAOUyAXkB+wOfAhkBDwEPAQYGSAXOCE8IQwQVCNsAcghfAI8AjwPImM2mYDPg7tMIA      <span class="token key atrule">project_off</span><span class="token punctuation">:</span>        <span class="token key atrule">command</span><span class="token punctuation">:</span>        <span class="token punctuation">-</span> raw<span class="token punctuation">:</span>nMwmMwlk0mk1mEsms3mEsmM2AEIAjJqAywA/gD+Bz4DPgIeAh4CHgy+BB4EHgMeAh4BHgReAz4A6TCAA<span class="token key atrule">switch</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">platform</span><span class="token punctuation">:</span> template    <span class="token key atrule">switches</span><span class="token punctuation">:</span>      <span class="token key atrule">projector</span><span class="token punctuation">:</span>        <span class="token key atrule">value_template</span><span class="token punctuation">:</span> <span class="token string">"&#123;&#123; states('input_boolean.projector') &#125;&#125;"</span>        <span class="token key atrule">turn_on</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> remote.send_command            <span class="token key atrule">data</span><span class="token punctuation">:</span>              <span class="token key atrule">command</span><span class="token punctuation">:</span>              <span class="token punctuation">-</span> project_on              <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> remote.xiaomi_miio_192_168_1_104          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> input_boolean.turn_on            <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> input_boolean.projector        <span class="token key atrule">turn_off</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> remote.send_command            <span class="token key atrule">data</span><span class="token punctuation">:</span>              <span class="token key atrule">command</span><span class="token punctuation">:</span>              <span class="token punctuation">-</span> project_off              <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> remote.xiaomi_miio_192_168_1_104          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> input_boolean.turn_off            <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> input_boolean.projector<span class="token key atrule">input_boolean</span><span class="token punctuation">:</span>  <span class="token key atrule">projector</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>音响也是一样，依葫芦画瓢就好了。</p><p>然后是 PC 这边，这里用了一个一个开源程序 <a href="https://github.com/KjetilSv/Win10As">Win10As</a> 然后通过 <a href="https://www.home-assistant.io/integrations/mqtt/">mqtt</a> 协议和 Home Assistant 连接。</p><p>设置三个指令：</p><table><thead><tr><th>name</th><th>cmdtext</th><th>cmdparameters</th></tr></thead><tbody><tr><td>exec&#x2F;plex</td><td>D:\plex.bat</td><td>1</td></tr><tr><td>display&#x2F;pc</td><td>D:\DisplaySwitch.exe</td><td>&#x2F;internal</td></tr><tr><td>display&#x2F;projector</td><td>D:\DisplaySwitch.exe</td><td>&#x2F;external</td></tr></tbody></table><p>其中 plex.bat：<code>start &quot;&quot; /B &quot;C:\Program Files\Plex\Plex Media Player\PlexMediaPlayer.exe&quot; --tv --fullscreen</code><br>DisplaySwitch.exe 位于 <code>C:\Windows\System32\DisplaySwitch.exe</code> 不知道为什么从 Win10As 中无法访问这个程序，不过把它拷贝出来也是一样用的。</p><p>然后可以在 Home Assistant 中加一个 pc_screen 的 switch：</p><pre class="line-numbers language-yaml" data-language="yaml"><code class="language-yaml"><span class="token key atrule">switch</span><span class="token punctuation">:</span>  <span class="token punctuation">-</span> <span class="token key atrule">platform</span><span class="token punctuation">:</span> template      <span class="token key atrule">pc_screen</span><span class="token punctuation">:</span>        <span class="token key atrule">value_template</span><span class="token punctuation">:</span> <span class="token string">"&#123;&#123; states('input_boolean.pc_screen') &#125;&#125;"</span>        <span class="token key atrule">turn_on</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> mqtt.publish            <span class="token key atrule">data</span><span class="token punctuation">:</span>              <span class="token key atrule">topic</span><span class="token punctuation">:</span> GAMEBOX/display/pc          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> input_boolean.turn_on            <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> input_boolean.pc_screen        <span class="token key atrule">turn_off</span><span class="token punctuation">:</span>          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> mqtt.publish            <span class="token key atrule">data</span><span class="token punctuation">:</span>              <span class="token key atrule">topic</span><span class="token punctuation">:</span> GAMEBOX/display/projector          <span class="token punctuation">-</span> <span class="token key atrule">service</span><span class="token punctuation">:</span> input_boolean.turn_on            <span class="token key atrule">entity_id</span><span class="token punctuation">:</span> input_boolean.pc_screen<span class="token key atrule">input_boolean</span><span class="token punctuation">:</span>  <span class="token key atrule">pc_screen</span><span class="token punctuation">:</span> <span class="token punctuation">&#123;</span><span class="token punctuation">&#125;</span><span aria-hidden="true" class="line-numbers-rows"><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span><span></span></span></code></pre><p>然后就可以通过 Automation 把它们串起来了。由于是 WebUI 就能配置的，我就不贴出来了。注意一点是在打开投影机到切换 PC 输出之间加一个延迟，等到投影 ready 再切换，切换后再加个延迟再启动 Plex 就能保证 Plex 在投影的窗口前台全屏显示了。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>其他的例如</p><ul><li>Hey Google, Turn on XXX 等单独的开关</li><li>Good Night 的时候同时关电脑，关投影</li><li>Google Assistant 控制 Alexa 设备</li><li>监控本月流量有没有超过 1T，在 80% 关掉 PT 上传</li><li>通过路由器监控接入设备，判断人在家的时候关闭摄像头监控</li><li>当阳台摄像头检测到移动，Google Home Mini 的喇叭鸣警笛。</li><li>当按照某种特定的顺序打开灯的时候，自动打开门，以防止出门忘带手机（前提是你能让 Google Home Mini 听到在门外的你）</li></ul><p>由于都是重用现有设备这里就不介绍了，这些都能通过 Home Assistant 接入后用 Automation 完成。</p><p>总之「智能家居」中的「智能」其实就是一个语音识别加上一个个预定的场景，很蠢，但是，<strong>真香</strong>。当习惯了叫一句 Hey Google 就能躺着沙发上开关各种设备之后，就再也回不去找各种遥控器了。比起一个「懂你」然后随时监听上传的设备，一个<a href="https://github.com/synesthesiam/rhasspy">离线语音识别</a>，加自定义的场景可能能更快地满足你对自动化的需要。</p><p>如果你有家居自动化的点子或者方案也可以留言交流，(´▽&#96;ʃ♡ƪ)</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;从 Google Assistant, Amazon Alexa, Apple Homekit 到米家，智能家居自动化已经不是什么新鲜的概念了。对于我来说，入坑的契机也非常简单：我不想下床关灯。然后随着想要自动化的场景增加，智能设备（可编程设备）就越来越多。这篇文章就根据自</summary>
      
    
    
    
    
    <category term="home-assistant" scheme="https://binux.blog/tags/home-assistant/"/>
    
    <category term="google-assistant" scheme="https://binux.blog/tags/google-assistant/"/>
    
    <category term="alexa" scheme="https://binux.blog/tags/alexa/"/>
    
    <category term="米家" scheme="https://binux.blog/tags/%E7%B1%B3%E5%AE%B6/"/>
    
  </entry>
  
  <entry>
    <title>Zerotier Nat 网关出口 和 iptables 调试</title>
    <link href="https://binux.blog/2019/03/zerotier-nat-gateway-and-iptables-debug/"/>
    <id>https://binux.blog/2019/03/zerotier-nat-gateway-and-iptables-debug/</id>
    <published>2019-03-02T06:48:44.000Z</published>
    <updated>2022-08-27T22:56:01.067Z</updated>
    
    <content type="html"><![CDATA[<p>每当看到各类教程中的 iptables 指令，在格式参数组合之下可以实现从防火墙，封禁 IP 端口到 NAT 的各种操作，就如同魔法一般，看不明白，却又感到无比强大。想学，但又好像不得要领，稍微不慎可能就再也连不上了。最近配置 Zerotier 的 Nat 网关的时候，看着 <a href="https://zerotier.atlassian.net/wiki/spaces/SD/pages/7110693/Overriding+Default+Route+Full+Tunnel+Mode">教程</a> 中的各种指令，抄过之后完全不通，花了3个晚上之后，逼着搞清楚了怎么 debug ( 打 log ) 后，终于配置成功 (虽然最终失败的原因和 iptables 无关)。</p><h2 id="Zerotier"><a href="#Zerotier" class="headerlink" title="Zerotier"></a>Zerotier</h2><p>首先介绍下 <a href="https://www.zerotier.com/">Zerotier</a> 和为什么要配置 Nat 网关。</p><p><a href="https://www.zerotier.com/">Zerotier</a> 是一个虚拟局域网软件，可以很简单地将无限量（社区服务器版100台）设备放入同一个虚拟局域网中。这样就能在任何网络环境中，访问家中的 NAS 或其他设备。反过来，如果将一台服务器加入这个局域网中，将它配置为一个 <a href="https://en.wikipedia.org/wiki/Network_address_translation">NAT</a> 网关，只要你加入这个虚拟局域网，就可以通过它连接世界。</p><p>选择 Zerotier 的原因是，它足够简单，只要一个 16 位的 network ID 就能实现组网了，相比我之前用过的 <a href="https://www.tinc-vpn.org/">tinc</a>，不需要节点 IP，不需要挨个配置节点，并且支持的操作系统广泛。</p><p>当然，第一步是<a href="http://www.zerotier.com/download.shtml">安装 Zerotier</a>，然后<a href="https://my.zerotier.com/">注册一个帐号</a>，<a href="https://my.zerotier.com/network">创建一个私人网络</a>。复制 network ID 在本地加入，然后回到网站中通过许可 (<code>Auth?</code>) 就好了。</p><p>当你将本地计算机和一台服务器加入网络后，然后就是根据 <a href="https://zerotier.atlassian.net/wiki/spaces/SD/pages/7110693/Overriding+Default+Route+Full+Tunnel+Mode">这个教程</a> 。运行下面4个命令就行了：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv4.ip_forward=1</span><br><span class="line">sudo iptables -t nat -A POSTROUTING -o eth0 -s 10.6.4.0/22 -j SNAT --to-source 45.32.69.220</span><br><span class="line">sudo iptables -A FORWARD -i zt+ -s 10.6.4.0/22 -d 0.0.0.0/0 -j ACCEPT</span><br><span class="line">sudo iptables -A FORWARD -i eth0 -s 0.0.0.0/0 -d 10.6.4.0/0 -j ACCEPT</span><br></pre></td></tr></table></figure><p>当然了，很明显，这里的 <code>eth0</code>, <code>10.6.4.0/22</code>, <code>45.32.69.220</code> 是需要根据实际环境替换的，<code>zt+</code> 是指的任何以 <code>zt</code> 开头的网络，zerotier 都是以这样的名字创建的，所以不用修改。这都可以通过 <code>ip addr</code> 或者 <code>ifconfig</code> 进行确认。比如在我的环境中，环境是这样的：</p><ul><li>网关外网 IP：123.45.67.89</li><li>zertier 网络: 192.168.11.0&#x2F;24</li><li>网关 zerotier 网络 IP: 192.168.11.1</li><li>本机 IP：192.168.11.20</li></ul><p>命令是这样的：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">sudo sysctl -w net.ipv4.ip_forward=1</span><br><span class="line">sudo iptables -t nat -A POSTROUTING -o venet0 -s 192.168.111.0/24 -j SNAT --to-source 123.45.67.89</span><br><span class="line">sudo iptables -A FORWARD -i zt+ -s 192.168.111.0/24 -d 0.0.0.0/0 -j ACCEPT</span><br><span class="line">sudo iptables -A FORWARD -i venet0 -s 0.0.0.0/0 -d 192.168.111.0/24 -j ACCEPT</span><br></pre></td></tr></table></figure><p>当我设置完了这些，然后把这个服务器设置为默认 0.0.0.0&#x2F;0 的网关之后，我断网了<br><del>如果这样有用的话，我岂不是就没机会学习 iptables 了。</del>  </p><h2 id="iptables"><a href="#iptables" class="headerlink" title="iptables"></a>iptables</h2><p>首先当然是把默认路由改回来。然后，如果只是为了调试，是不需要设置默认路由的，或者说最好不要设置默认路由到这台机器上的，你可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># macos</span></span><br><span class="line">sudo route add -net 98.76.54.32 192.168.111.1</span><br><span class="line"><span class="comment"># linux</span></span><br><span class="line"><span class="comment"># sudo route add -net 98.76.64.32 gw 192.168.111.1</span></span><br></pre></td></tr></table></figure><p>设置一条单独的路由，到另一台主机上，然后就可以单独监控调试这条链路的情况了。</p><h3 id="LOG-和-TRACE"><a href="#LOG-和-TRACE" class="headerlink" title="LOG 和 TRACE"></a>LOG 和 TRACE</h3><p>好了，既然现在网络不通，我最想知道的当然是哪断了。</p><h4 id="本机-gt-网关"><a href="#本机-gt-网关" class="headerlink" title="本机 -&gt; 网关"></a>本机 -&gt; 网关</h4><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t raw -A PREROUTING -p TCP -s 192.168.111.20 -j LOG</span><br></pre></td></tr></table></figure><p>这里就给所有从 本机 发往 网关 的 TCP 数据包打了 LOG，然后 <code>tail -f /var/log/messages</code> （或者 <code>tail -f /var/log/kern.log</code>) 追踪日志。<br>现在你可以从本地往测试服务器发个请求： <code>curl 98.76.54.32</code>，如果在日志中看到</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">Mar  2 15:53:14 myserver kernel: [5377966.960574] IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=45807 DF PROTO=TCP SPT=64408 DPT=80 WINDOW=65535 RES=0x00 SYN URGP=0</span><br></pre></td></tr></table></figure><p>那么就可以确认网关确实收到这个包了</p><h4 id="网关-gt-网站"><a href="#网关-gt-网站" class="headerlink" title="网关 -&gt; 网站"></a>网关 -&gt; 网站</h4><p>然后可以用 TRACE 追踪这个包是否触发了 NAT。</p><blockquote><p>在一些环境中，你可能需要开启 TRACE 内核支持，参考 <a href="https://serverfault.com/questions/385937/how-to-enable-iptables-trace-target-on-debian-squeeze-6">How to Enable IPtables TRACE Target on Debian Squeeze (6)</a></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t raw -A PREROUTING -p TCP -s 192.168.111.20 -j TRACE </span><br></pre></td></tr></table></figure><p>你会看到</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921579] IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921611] TRACE: raw:PREROUTING:policy:3 IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921645] TRACE: mangle:PREROUTING:policy:1 IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921672] TRACE: nat:PREROUTING:policy:1 IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921698] TRACE: mangle:FORWARD:policy:1 IN=zthnhi321 OUT=venet0 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921719] TRACE: filter:FORWARD:rule:1 IN=zthnhi321 OUT=venet0 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921741] TRACE: mangle:POSTROUTING:policy:1 IN= OUT=venet0 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br><span class="line">Mar  2 15:58:11 myserver kernel: [5378263.921763] TRACE: nat:POSTROUTING:rule:1 IN= OUT=venet0 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=63 ID=32766 DF PROTO=TCP SPT=65087 DPT=80 SEQ=3874826404 ACK=0 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0 OPT (02040ACA2C84454E80103030501000004010800000020000)</span><br></pre></td></tr></table></figure><p>表明这个包分别经过了</p><ul><li>raw:PREROUTING:policy:3</li><li>mangle:PREROUTING:policy:1</li><li>nat:PREROUTING:policy:1</li><li>mangle:FORWARD:policy:1</li><li>filter:FORWARD:rule:1</li><li>mangle:POSTROUTING:policy:1</li><li>nat:POSTROUTING:rule:1</li></ul><p>你可以通过</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t nat -nvL --line-numbers</span><br></pre></td></tr></table></figure><p>查看对应的规则编号。在这里，可以看到 <code>filter:FORWARD:rule:1</code> 和 <code>nat:POSTROUTING:rule:1</code> 被触发了。即</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">sudo iptables -A FORWARD -i zt+ -s 192.168.111.0/24 -d 0.0.0.0/0 -j ACCEPT</span><br><span class="line">sudo iptables -t nat -A POSTROUTING -o venet0 -s 192.168.111.0/24 -j SNAT --to-source 123.45.67.89</span><br></pre></td></tr></table></figure><blockquote><p>另外如果你尝试过执行 <code>iptables -t nat -A POSTROUTING -i zt+ -o venet0</code> ，会收到 <code>Can&#39;t use -i with POSTROUTING</code> 报错。从 TRACE 中可以看出 <code>nat:POSTROUTING:rule:1</code> 中 <code>IN=</code> 是空的。所以在 <code>POSTROUTING</code> 表中是不能使用 <code>-i</code> 指定入包接口的。</p></blockquote><h4 id="网站-gt-网关-gt-本机"><a href="#网站-gt-网关-gt-本机" class="headerlink" title="网站 -&gt; 网关 -&gt; 本机"></a>网站 -&gt; 网关 -&gt; 本机</h4><p>这次我们一步到位</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">iptables -t raw -A PREROUTING -p TCP -s 98.76.54.32 -j LOG</span><br><span class="line">iptables -t raw -A PREROUTING -p TCP -s 98.76.54.32 -j TRACE</span><br></pre></td></tr></table></figure><p>另外为了防止日志太多，这里可以把刚才添加的那条 TRACE 删掉：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">iptables -t raw -D PREROUTING -p TCP -s 192.168.111.20 -j TRACE </span><br></pre></td></tr></table></figure><p>再次 <code>curl 98.76.54.32</code> 就能看到包返回了</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771146] IN=zthnhi321 OUT= MAC=88:55:bb:99:88:88:88:66:11:dd:ff:bb:00:00 SRC=192.168.111.20 DST=98.76.54.32 LEN=64 TOS=0x00 PREC=0x00 TTL=64 ID=64965 DF PROTO=TCP SPT=57286 DPT=80 WINDOW=65535 RES=0x00 CWR ECE SYN URGP=0</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771696] IN=venet0 OUT= MAC= SRC=98.76.54.32 DST=123.45.67.89 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771713] TRACE: raw:PREROUTING:policy:4 IN=venet0 OUT= MAC= SRC=98.76.54.32 DST=123.45.67.89 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 SEQ=1319922288 ACK=3993987234 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0 OPT (020401AA7250238401080A2F75F14B4048030307)</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771729] TRACE: mangle:PREROUTING:policy:1 IN=venet0 OUT= MAC= SRC=98.76.54.32 DST=123.45.67.89 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 SEQ=1319922288 ACK=3993987234 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0 OPT (020401AA7250238401080A2F75F14B4048030307)</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771743] TRACE: mangle:FORWARD:policy:1 IN=venet0 OUT=zthnhi321 SRC=98.76.54.32 DST=192.168.111.20 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 SEQ=1319922288 ACK=3993987234 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0 OPT (020401AA7250238401080A2F75F14B4048030307)</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771755] TRACE: filter:FORWARD:rule:2 IN=venet0 OUT=zthnhi321 SRC=98.76.54.32 DST=192.168.111.20 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 SEQ=1319922288 ACK=3993987234 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0 OPT (020401AA7250238401080A2F75F14B4048030307)</span><br><span class="line">Mar  3 14:04:55 myserver kernel: [5457820.771767] TRACE: mangle:POSTROUTING:policy:1 IN= OUT=zthnhi321 SRC=98.76.54.32 DST=192.168.111.20 LEN=60 TOS=0x00 PREC=0x00 TTL=55 ID=0 DF PROTO=TCP SPT=80 DPT=57286 SEQ=1319922288 ACK=3993987234 WINDOW=14480 RES=0x00 ECE ACK SYN URGP=0 OPT (020401AA7250238401080A2F75F14B4048030307)</span><br></pre></td></tr></table></figure><p>同理，可以看到数据包在经过 <code>mangle:PREROUTING:policy:1</code> 之后，DST 被改写回了 <code>192.168.111.20</code>。于是一次成功的 NAT 就完成了。</p><p>最后，这里有一张图，显示了数据包都会经过什么表:</p><p><a title="Jan Engelhardt [CC BY-SA 3.0 (https://creativecommons.org/licenses/by-sa/3.0)], via Wikimedia Commons" href="https://commons.wikimedia.org/wiki/File:Netfilter-packet-flow.svg"><img width="512" alt="Netfilter-packet-flow" src="https://upload.wikimedia.org/wikipedia/commons/thumb/3/37/Netfilter-packet-flow.svg/512px-Netfilter-packet-flow.svg.png"></a></p><blockquote><p>之前配置 NAT 网关不成功的原因是：zerotier 防火墙错误设置了如下规则，导致包没法发回本机。</p></blockquote><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">drop</span><br><span class="line">not chr ipauth</span><br><span class="line">;</span><br></pre></td></tr></table></figure><h2 id="网关"><a href="#网关" class="headerlink" title="网关+"></a>网关+</h2><p>既然有网关了，我就想能不能再搞个智能回国网关。，只要我连上这个局域网，就能听网易云音乐了。我用的 vnet.one 用的是 anyconnect 连接，它有一个开源实现 openconnect，于是我<a href="https://stackoverflow.com/questions/38369950/openconnect-not-able-to-connect-to-gateway/42342253">这样</a>：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">sudo apt-get install curl vpnc-scripts build-essential libssl-dev libxml2-dev liblz4-dev</span><br><span class="line">wget ftp://ftp.infradead.org/pub/openconnect/openconnect-8.02.tar.gz</span><br><span class="line">tar xzf openconnect-8.02.tar.gz</span><br><span class="line"><span class="built_in">cd</span> openconnect-8.02</span><br><span class="line">./configure --without-gnutls --with-vpnc-script=/usr/share/vpnc-scripts/vpnc-script</span><br><span class="line">make</span><br><span class="line">sudo make install</span><br><span class="line">sudo ldconfig /usr/local/lib</span><br></pre></td></tr></table></figure><p>然后用 <a href="https://github.com/ashi009/bestroutetb">bestroutetb</a> 生成个路由：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">bestroutetb --route.net=US,GB  --route.vpn=CN -p json -o routes.json -f</span><br><span class="line">jq <span class="string">&#x27;.[] | select(.gateway == &quot;vpn&quot;) | .prefix + &quot;/&quot; + (.length | tostring)&#x27;</span>  routes.json  -c -r &gt; routes.cn</span><br></pre></td></tr></table></figure><p>整个设置路由的脚本</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">#!/bin/bash</span></span><br><span class="line"><span class="built_in">source</span> /root/.bashrc</span><br><span class="line"></span><br><span class="line">DIR=$(<span class="built_in">dirname</span> <span class="variable">$0</span>)</span><br><span class="line"></span><br><span class="line"><span class="comment"># Routes that we want to be used by the VPN link</span></span><br><span class="line">ROUTES=`<span class="built_in">cat</span> <span class="variable">$DIR</span>/routes.cn`</span><br><span class="line"></span><br><span class="line"><span class="comment"># Helpers to create dotted-quad netmask strings.</span></span><br><span class="line">MASKS[1]=<span class="string">&quot;128.0.0.0&quot;</span></span><br><span class="line">MASKS[2]=<span class="string">&quot;192.0.0.0&quot;</span></span><br><span class="line">MASKS[3]=<span class="string">&quot;224.0.0.0&quot;</span></span><br><span class="line">MASKS[4]=<span class="string">&quot;240.0.0.0&quot;</span></span><br><span class="line">MASKS[5]=<span class="string">&quot;248.0.0.0&quot;</span></span><br><span class="line">MASKS[6]=<span class="string">&quot;252.0.0.0&quot;</span></span><br><span class="line">MASKS[7]=<span class="string">&quot;254.0.0.0&quot;</span></span><br><span class="line">MASKS[8]=<span class="string">&quot;255.0.0.0&quot;</span></span><br><span class="line">MASKS[9]=<span class="string">&quot;255.128.0.0&quot;</span></span><br><span class="line">MASKS[10]=<span class="string">&quot;255.192.0.0&quot;</span></span><br><span class="line">MASKS[11]=<span class="string">&quot;255.224.0.0&quot;</span></span><br><span class="line">MASKS[12]=<span class="string">&quot;255.240.0.0&quot;</span></span><br><span class="line">MASKS[13]=<span class="string">&quot;255.248.0.0&quot;</span></span><br><span class="line">MASKS[14]=<span class="string">&quot;255.252.0.0&quot;</span></span><br><span class="line">MASKS[15]=<span class="string">&quot;255.254.0.0&quot;</span></span><br><span class="line">MASKS[16]=<span class="string">&quot;255.255.0.0&quot;</span></span><br><span class="line">MASKS[17]=<span class="string">&quot;255.255.128.0&quot;</span></span><br><span class="line">MASKS[18]=<span class="string">&quot;255.255.192.0&quot;</span></span><br><span class="line">MASKS[19]=<span class="string">&quot;255.255.224.0&quot;</span></span><br><span class="line">MASKS[20]=<span class="string">&quot;255.255.240.0&quot;</span></span><br><span class="line">MASKS[21]=<span class="string">&quot;255.255.248.0&quot;</span></span><br><span class="line">MASKS[22]=<span class="string">&quot;255.255.252.0&quot;</span></span><br><span class="line">MASKS[23]=<span class="string">&quot;255.255.254.0&quot;</span></span><br><span class="line">MASKS[24]=<span class="string">&quot;255.255.255.0&quot;</span></span><br><span class="line">MASKS[25]=<span class="string">&quot;255.255.255.128&quot;</span></span><br><span class="line">MASKS[26]=<span class="string">&quot;255.255.255.192&quot;</span></span><br><span class="line">MASKS[27]=<span class="string">&quot;255.255.255.224&quot;</span></span><br><span class="line">MASKS[28]=<span class="string">&quot;255.255.255.240&quot;</span></span><br><span class="line">MASKS[29]=<span class="string">&quot;255.255.255.248&quot;</span></span><br><span class="line">MASKS[30]=<span class="string">&quot;255.255.255.252&quot;</span></span><br><span class="line">MASKS[31]=<span class="string">&quot;255.255.255.254&quot;</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">export</span> CISCO_SPLIT_INC=0</span><br><span class="line"></span><br><span class="line"><span class="comment"># Create environment variables that vpnc-script uses to configure network</span></span><br><span class="line"><span class="keyword">function</span> <span class="function"><span class="title">addroute</span></span>()</span><br><span class="line">&#123;</span><br><span class="line">    <span class="built_in">local</span> ROUTE=<span class="string">&quot;<span class="variable">$1</span>&quot;</span></span><br><span class="line">    <span class="built_in">export</span> CISCO_SPLIT_INC_<span class="variable">$&#123;CISCO_SPLIT_INC&#125;</span>_ADDR=<span class="variable">$&#123;ROUTE%%/*&#125;</span></span><br><span class="line">    <span class="built_in">export</span> CISCO_SPLIT_INC_<span class="variable">$&#123;CISCO_SPLIT_INC&#125;</span>_MASKLEN=<span class="variable">$&#123;ROUTE##*/&#125;</span></span><br><span class="line">    <span class="built_in">export</span> CISCO_SPLIT_INC_<span class="variable">$&#123;CISCO_SPLIT_INC&#125;</span>_MASK=<span class="variable">$&#123;MASKS[<span class="variable">$&#123;ROUTE##*/&#125;</span>]&#125;</span></span><br><span class="line">    <span class="built_in">export</span> CISCO_SPLIT_INC=$((<span class="variable">$&#123;CISCO_SPLIT_INC&#125;</span>+<span class="number">1</span>))</span><br><span class="line">&#125;</span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> r <span class="keyword">in</span> <span class="variable">$ROUTES</span>; <span class="keyword">do</span></span><br><span class="line">    addroute <span class="variable">$r</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="keyword">for</span> l <span class="keyword">in</span> <span class="variable">$INTERNAL_IP4_DNS</span>; <span class="keyword">do</span></span><br><span class="line">    <span class="keyword">if</span> [ <span class="variable">$reason</span> = <span class="string">&quot;connect&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        iptables -t nat -A PREROUTING -i zt+ -p udp --dport 53 -j DNAT --to <span class="variable">$l</span></span><br><span class="line">    <span class="keyword">elif</span> [ <span class="variable">$reason</span> = <span class="string">&quot;disconnect&quot;</span> ]; <span class="keyword">then</span></span><br><span class="line">        iptables -t nat -D PREROUTING -i zt+ -p udp --dport 53 -j DNAT --to <span class="variable">$l</span></span><br><span class="line">    <span class="keyword">fi</span></span><br><span class="line">    <span class="built_in">break</span></span><br><span class="line"><span class="keyword">done</span></span><br><span class="line"></span><br><span class="line"><span class="built_in">exec</span> /usr/share/vpnc-scripts/vpnc-script</span><br></pre></td></tr></table></figure><p>整合一下</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="built_in">echo</span> <span class="string">&quot;password&quot;</span> | openconnect address.example.org -u username --passwd-on-stdin --non-inter --script /root/openconnect/script.sh</span><br></pre></td></tr></table></figure><p>完成。只不过，如果要看 bilibili 还需要设置 DNS 到国内，或者设置到网关上（上面的脚本配置了 DNS 转发）。而且 zerotier 只是为了虚拟局域网设计的，不如 anyconnect 能自动设置网关，路由，DNS方便。不过挺好玩的，还学了不少东西，over。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;每当看到各类教程中的 iptables 指令，在格式参数组合之下可以实现从防火墙，封禁 IP 端口到 NAT 的各种操作，就如同魔法一般，看不明白，却又感到无比强大。想学，但又好像不得要领，稍微不慎可能就再也连不上了。最近配置 Zerotier 的 Nat 网关的时候，看着</summary>
      
    
    
    
    
    <category term="zerotier" scheme="https://binux.blog/tags/zerotier/"/>
    
    <category term="nat gateway" scheme="https://binux.blog/tags/nat-gateway/"/>
    
    <category term="full tunnel mode" scheme="https://binux.blog/tags/full-tunnel-mode/"/>
    
    <category term="iptables" scheme="https://binux.blog/tags/iptables/"/>
    
  </entry>
  
  <entry>
    <title>少女前线拖尸脚本 和 生成它的可视化工具</title>
    <link href="https://binux.blog/2018/10/girls-frontline-ankulua-vision/"/>
    <id>https://binux.blog/2018/10/girls-frontline-ankulua-vision/</id>
    <published>2018-10-14T22:22:15.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>最近在玩少女前线，这是一个手机游戏，over。不是，就真的没有什么好讲的嘛，了解的人早有耳闻，不了解的就只要知道这是个手机游戏就好了，嗯。</p><p>然后，我会好好地，正常地，氪金地去玩这个游戏吗？不可能的，玩游戏哪有破解它有意思呢。当年破解 Ingress 是因为它用的 HTTPS 通信的，算是本行。百万亚瑟王是因为别人已经逆向好了，我只是写了一些 bot。现在这么办，玩不了了吗？作为一个不会安卓，不会逆向，不会汇编的菜鸡，那我只好上按键精灵了啊。于是乎，我找到了这个： <a href="http://ankulua-tw.boards.net/thread/2/ankulua">AnkuLua</a></p><blockquote><p>AnkuLua 是一個專注在自動化的Android App<br>基本自動化動作有:</p><ul><li>抓取螢幕並找尋指定圖案 </li><li>對找圖結果採取使用者要的動作(例如點擊、抓放(drag and drop)、打字…等等)</li></ul></blockquote><p>最重要的是，它能运行 lua 脚本！虽然我是一个不会安卓，不会逆向，不会汇编的菜鸡，但是我会 lua 啊。</p><h3 id="ankulua-vision"><a href="#ankulua-vision" class="headerlink" title="ankulua-vision"></a>ankulua-vision</h3><p>不过，在使用过程中发现，找寻指定图案，需要不断截图&#x2F;裁剪，这样太麻烦了。于是我又用 electron 做了一个可视化的截图资源管理器 <a href="https://github.com/binux/ankulua-vision">ankulua-vision</a>，像这样的：</p><p><img src="https://raw.githack.com/binux/ankulua-vision/master/static/Screenshot.png" alt="screenshot"></p><p>基本思路就是，一般游戏是由众多 UI 界面组成的，点击某个按钮能跳转到某个界面上去。那么通过截图，标注<strong>识别区域</strong>，那么程序就能知道游戏现在所处的界面。通过标注<strong>按钮区域</strong>，那么只需要 <code>goto(&#39;battle&#39;)</code>，程序就能自动规划从当前界面到 battle 的可行路径，然后点啊点啊就完成需要的操作了。这样一方面不需要自己去裁剪图片了，另一方面通过框架代码，在运行过程中能够有更多的错误检查，自动应对可能出现的各种异常。</p><p>理论上，对于点啊点的游戏，是能实现无代码的。即使不能，对于复杂的动作，也可以通过 lua 拓展。</p><p>源码在这里：<a href="https://github.com/binux/ankulua-vision">https://github.com/binux/ankulua-vision</a>  </p><p>你依旧需要在安卓手机或者模拟器中安装 ankulua，然后加载生成的 start.lua 脚本。默认自带了一个简单的循环逻辑，运行后可以直接图形化界面配置运行。当然你也可以通过 lua 脚本拓展，除了 ankulua 本身的 API 可用之外，你也可以使用 <code>stateMachine</code> 这套界面跳转逻辑 API，重用简化步骤。<code>stateMachine</code> 的 API 在 README 中有简略的文档说明。</p><p><img src="/assets/image/MuMu20181014200018.png" alt="setting screenshot"></p><p>源码使用 GPLv3 或 MIT 许可证，取决于第一个有效 PR（例如 fix typo 不算），如果第一个 PR 之前有商业化需求或者 PR 作者要求，则 MIT。</p><h3 id="少女前线拖尸脚本"><a href="#少女前线拖尸脚本" class="headerlink" title="少女前线拖尸脚本"></a>少女前线拖尸脚本</h3><p><strong>WARNING: 任何使用脚本的行为都是官方禁止的，我不对下文所述任何内容以及其后果负责</strong></p><p>于是，这里就是 少女前线的拖尸脚本：</p><p><a href="https://github.com/binux/binux_github_com/releases/download/gf/shojo.zip">https://github.com/binux/binux_github_com/releases/download/gf/shojo.zip</a></p><p>同时它也是一个 ankulua-vision 的项目，你可以通过 ankulua-vision 打开这个项目目录，调整截屏或者按钮位置。</p><h4 id="脚本实现的功能"><a href="#脚本实现的功能" class="headerlink" title="脚本实现的功能"></a>脚本实现的功能</h4><ul><li>43e, 02, 52n 拖尸</li><li>自动重启后勤</li><li>自动强化或者分解人形</li><li>自动修理</li></ul><h4 id="使用方法"><a href="#使用方法" class="headerlink" title="使用方法"></a>使用方法</h4><ol><li>根据 <a href="http://bbs.nga.cn/read.php?tid=13670657">[填坑结束？][失了智]萌新向拖尸教学帖[更新8-1N相关]</a> 一文准备好打手和阵型，一队练级队，二队补给队，52n 还需要 3 队狗粮队。</li><li>解压拷贝脚本到手机中，在 ankulua 中加载 start.lua。</li><li>在启动界面中选择你的两个打手（每轮结束后，两个打手会交换），选择拖尸任务，如果仅自动后勤，选择 null 就好了。</li></ol><p>其中 52n 会在战斗中撤退 5, 8 号位 （见 NGA 文 “43e的说明” 展开部分），02 在选择 m4a1 时会撤退 1, 7 号位。</p><p><img src="/assets/image/MuMu20181014200007.png" alt="setting screenshot"></p><p>然后开始吧！</p><p><strong>WARNING: 任何使用脚本的行为都是官方禁止的，我不对上文所述任何内容以及其后果负责</strong></p><p>over</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;最近在玩少女前线，这是一个手机游戏，over。不是，就真的没有什么好讲的嘛，了解的人早有耳闻，不了解的就只要知道这是个手机游戏就好了，嗯。&lt;/p&gt;
&lt;p&gt;然后，我会好好地，正常地，氪金地去玩这个游戏吗？不可能的，玩游戏哪有破解它有意思呢。当年破解 Ingress 是因为它用</summary>
      
    
    
    
    
    <category term="少女前线" scheme="https://binux.blog/tags/%E5%B0%91%E5%A5%B3%E5%89%8D%E7%BA%BF/"/>
    
    <category term="ankulua" scheme="https://binux.blog/tags/ankulua/"/>
    
    <category term="ankulua-vision" scheme="https://binux.blog/tags/ankulua-vision/"/>
    
    <category term="安卓" scheme="https://binux.blog/tags/%E5%AE%89%E5%8D%93/"/>
    
    <category term="自动化" scheme="https://binux.blog/tags/%E8%87%AA%E5%8A%A8%E5%8C%96/"/>
    
    <category term="open-source" scheme="https://binux.blog/tags/open-source/"/>
    
    <category term="github" scheme="https://binux.blog/tags/github/"/>
    
  </entry>
  
  <entry>
    <title>2018 新的冒险</title>
    <link href="https://binux.blog/2018/02/us/"/>
    <id>https://binux.blog/2018/02/us/</id>
    <published>2018-02-08T05:04:03.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>真的又是好久没有写 blog 了。</p><p>年纪大了，记忆力下降，没有学习新东西的动力，也没精力折腾新的技术，新的领域了。每天就是看看斗鱼，打打游戏就过去了，现在的理想就是早点退休，当条咸鱼就好了。</p><p>2017 年主要给公司开发了一套基于 electron (chromium) 的页面渲染后端，可以保证抓取时和用户浏览器中看到的保持一致。同时这个服务器端的浏览器，可以通过 websocket 连接用户浏览器，双向同步页面内容变化，录下用户操作，在抓取时进行重放。这些功能我真的很想做给 pyspider，但是确实不方便。眼见着 pyspider stars 过万，而我却渐渐没有精力去维护了。我的希望是以后从现在的公司离职之后能有2-6个月全职开发 pyspider，算是这几年项目荒废的补偿吧。</p><p>公司终于把伦敦办公室关闭了，我也随着搬到了美国（湾区）。随便写一点美国的感受吧：</p><ul><li>加州税真高，比英国还高，英国人家好歹有免费医保啊</li><li>美国真的是物资极大的丰富，真的可以理解为什么很多中国人来了就想要留下来，小富即安<ul><li>地广人稀，使得超市都是 super 起步的，这样会让选择非常多，卖的量都是加大号的</li><li>充足的停车场，汽车出行不用担心不方便停车</li><li>汽车让生活半径极大扩大，湾区各种中餐半小时车程都能到达，而半小时车程也不过是正常通勤所花的时间</li><li>各种服务比起英国齐全多了，而且周六日不休</li><li>apartment 社区大都自带 365 天 7 * 24 开放恒温游泳池，健身房等设施（即使大冬天根本没有人去用，水也是恒温并更新的）</li></ul></li><li>非实时记账，很多场合真的需要使用支票，需要通过账单付费；因为是后付费，需要 SSN 查询你的信用记录。真的很不方便。</li><li>租房好贵，宽带好贵，手机卡好贵，小费好贵</li></ul><p>总体来说，英国更接近国内的政府+生活模式，而美国是只要你花钱，什么都有，不花钱，滚蛋。反正 L1 签证也就 3 年，也不能跳槽，而且就美国这个 H1B 抽奖 + 绿卡排队，比起英国来简直就是地狱模式。趁着这几年，在美国多玩一玩吧。9酱。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;真的又是好久没有写 blog 了。&lt;/p&gt;
&lt;p&gt;年纪大了，记忆力下降，没有学习新东西的动力，也没精力折腾新的技术，新的领域了。每天就是看看斗鱼，打打游戏就过去了，现在的理想就是早点退休，当条咸鱼就好了。&lt;/p&gt;
&lt;p&gt;2017 年主要给公司开发了一套基于 electron</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>Data Highlighter</title>
    <link href="https://binux.blog/2016/12/data-highlighter/"/>
    <id>https://binux.blog/2016/12/data-highlighter/</id>
    <published>2016-12-04T21:19:10.000Z</published>
    <updated>2022-08-27T22:56:01.067Z</updated>
    
    <content type="html"><![CDATA[<p>又是好久没有写 blog 了。现在确实没有上学的时候愿意折腾了，能用钱解决的问题，就不自己动手了。但是，很久不写 blog 这事呢，其实就是因为懒 _ (:3」∠) _。</p><p>这里带来的是 <a href="/2014/07/how-to-extract-data-from-web/"><br>如何从 WEB 页面中提取信息</a> 一文中提到的 data highlighter。但是由于开源需要重写代码，而我并不打算使用它，这里只给出 <a href="https://demo.binux.me/data_highlighter.html">demo</a> 和算法思路。</p><h2 id="简介"><a href="#简介" class="headerlink" title="简介"></a>简介</h2><p>Data Highlighter 其实是一种生成提取规则的方式：</p><blockquote><p>Data Highlighter 的标注方式是：给一系列相似的页面，让用户标出（高亮）每个属性在页面中的位置。通过多个页面的标注信息，寻找每个属性的特征。当然了，这个特征可以是 xpath，也可以是上下文，也有可能是机器学习的特征向量。<br>Data Hightlighter 通过高亮 多个页面中相同属性 进行规则学习，省去了人为设置规则时的学习成本。实践表明，在单一页面模板下，标记2个页面就足以生成规则了。效率远大于手工设置规则。Google Data Highlighter 甚至对文字进行了切分，能在 英语 &#x2F; 汉语普通话 &#x2F; 粤语 xpath 相同的情况下，分别选出三种语言。是我目前见过的成熟度最高、通用性最好、最简便的数据抽取方式。</p></blockquote><p>那我们通过例子介绍一下使用方式。首先打开 <a href="https://demo.binux.me/data_highlighter.html">demo</a>。这里列出了5个豆瓣电影的 sample 页面，点击 go 加载页面。将鼠标放在页面中，就会发现文字被高亮了，点击拖拽鼠标选择需要提取的文字，在弹出的菜单中选择属性名。</p><br><p><video controls autoplay loop src="/assets/image/screen-data-highlighter-select.mp4"></video></p><p>然后分别点击 <code>gen_tpl</code> 和 <code>test_all</code> 就能看到生成的模板，以及提取效果了。</p><p>![extraction sample](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-12-04 14.44.18.png)</p><h2 id="算法解析"><a href="#算法解析" class="headerlink" title="算法解析"></a>算法解析</h2><p>点击 <code>gen_tpl</code> 就可以看到生成的模板了，<code>tpl</code> 字段的 key 为抽取的变量的名字，value 描述了一个 <a href="https://zh.wikipedia.org/wiki/%E6%9C%89%E9%99%90%E7%8A%B6%E6%80%81%E6%9C%BA">状态机</a>。</p><p>先看一个简单的例子，以下就是对 <code>name</code> 字段的模板，它描述了一个 <code>s0 -&gt; e0</code> 的状态机。</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><span class="line"><span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;need_more_sample&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">true</span></span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;tips&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span><span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;tpl&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">    <span class="attr">&quot;name&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">      <span class="attr">&quot;states&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">        <span class="attr">&quot;s0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;start&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;transitions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">            <span class="string">&quot;e0&quot;</span></span><br><span class="line">          <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;xpath&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/html/body/div/div/h1/span/textnode&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;features&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">              <span class="attr">&quot;exclude&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">              <span class="attr">&quot;include&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;ancestor::*[1][name()=\&quot;span\&quot; and @property=&#x27;v:itemreviewed&#x27;]&quot;</span></span><br><span class="line">              <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">        <span class="attr">&quot;e0&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">          <span class="attr">&quot;tag&quot;</span><span class="punctuation">:</span> <span class="string">&quot;end&quot;</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;transitions&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">          <span class="attr">&quot;condition&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">            <span class="attr">&quot;xpath&quot;</span><span class="punctuation">:</span> <span class="string">&quot;/html/body/div/div/h1/span/textnode&quot;</span><span class="punctuation">,</span></span><br><span class="line">            <span class="attr">&quot;features&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">              <span class="attr">&quot;exclude&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;following::*[position()=1 and name()=\&quot;textnode\&quot;]&quot;</span></span><br><span class="line">              <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">              <span class="attr">&quot;include&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">                <span class="string">&quot;ancestor::*[1]/*[last()-0] = ancestor-or-self::*[1]&quot;</span></span><br><span class="line">              <span class="punctuation">]</span></span><br><span class="line">            <span class="punctuation">&#125;</span></span><br><span class="line">          <span class="punctuation">&#125;</span></span><br><span class="line">        <span class="punctuation">&#125;</span></span><br><span class="line">      <span class="punctuation">&#125;</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;entrance_state&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">        <span class="string">&quot;s0&quot;</span></span><br><span class="line">      <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;is_list&quot;</span><span class="punctuation">:</span> <span class="literal"><span class="keyword">false</span></span><span class="punctuation">,</span></span><br><span class="line">      <span class="attr">&quot;data_type&quot;</span><span class="punctuation">:</span> <span class="string">&quot;TEXT&quot;</span></span><br><span class="line">    <span class="punctuation">&#125;</span></span><br><span class="line">  <span class="punctuation">&#125;</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><blockquote><p>直接跳到 <code>tpl.name</code> 部分，它有4个字段，<code>is_list</code> 和 <code>data_type</code> 描述了字段的类型，它们在字段定义的时候就已经指定了，没什么好说的。<code>states</code> 和 <code>entrance_state</code> 为状态机的描述部分。</p></blockquote><blockquote><p><code>entrance_state</code> 表示状态机的入口为 <code>s0</code>。</p><p><code>states</code> 中描述了两个状态 <code>s0</code> 和 <code>e0</code>。 <code>s0.tag == start</code> 表示这是一个开始状态，即标示字段提取的开头，<code>e0.tag == end</code> 为结束状态，即字段的结尾。<code>s0.transitions == [e0]</code> 表示从 <code>s0</code> 能够转移到 <code>e0</code>，而由于 <code>e0.tag == end</code> 已经结束了，所以就没有转移状态了。<br><br><br>在执行时，<a href="https://zh.wikipedia.org/wiki/%E6%A0%91%E7%9A%84%E9%81%8D%E5%8E%86#.E5.85.88.E5.BA.8F.E9.81.8D.E5.8E.86.28Pre-Order_Traversal.29">先序遍历</a> DOM 树，根据 <code>condition</code> 的条件进行状态转移。</p></blockquote><blockquote><p><code>s0.condition</code> 表示进入开始条件为：xpath <code>/html/body/div/div/h1/span/textnode</code> 并且满足 <code>ancestor::*[1][name()=\&quot;span\&quot; and @property=&#39;v:itemreviewed&#39;]</code>（父元素的 name 为 span，property 属性为 “v:itemreviewed”) 这个特征。  </p></blockquote><blockquote><p>而进入结束条件为 <code>e0.condition</code>： xpath <code>/html/body/div/div/h1/span/textnode</code> 并且满足 <code>ancestor::*[1]/*[last()-0] = ancestor-or-self::*[1]</code>（最后一个元素），并排除满足 <code>following::*[position()=1 and name()=\&quot;textnode\&quot;]</code>（右兄弟为 textnode，实际与 include 互斥）的元素。</p></blockquote><blockquote><p><strong>简单地说，这个状态机描述了 <code>属性 property=&#39;v:itemviewed&#39; 的 span 的所有 textnode 孩子</code> 这样一条规则。</strong></p></blockquote><blockquote><p>而多状态的执行也是类似的，只不过它可能存在状态分支，或者在多个状态间循环。不过只要根据状态转移条件状态进行转移，再根据 <code>tag</code> 所标识的开始结束进行提取即可。</p></blockquote><p>为什么要使用状态机在后面的小结讲解，我们暂且将整个状态机理解为「描述字段提取的开头和结尾」，每个状态就描述了开头结尾的特征。先来看看状态是如何描述「字段提取的开头和结尾」的。</p><h3 id="状态条件的生成"><a href="#状态条件的生成" class="headerlink" title="状态条件的生成"></a>状态条件的生成</h3><p>算法的基本思路是<strong>寻找多个样本间相同的特征，并使得特征排除其他相似元素</strong>。</p><p>每一个元素可以根据 id, class 属性，文字内容，位置，前 n 个元素的特征，祖先元素特征生成一组特征集合。对多个样本的特征取交，对需要排除的元素取差。</p><p>例如如果每次都选择第二个「豆瓣成员常用的标签」，就会生成</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;features&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;exclude&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;preceding::*[position()=2 and name()=\&quot;textnode\&quot;]&quot;</span></span><br><span class="line">  <span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;include&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;preceding::*[position()=2 and name()=\&quot;a\&quot;]&quot;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br><span class="line"><span class="punctuation">&#125;</span></span><br></pre></td></tr></table></figure><p>如果每次都选择 2016 的标签，就会生成</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">&quot;features&quot;</span><span class="punctuation">:</span> <span class="punctuation">&#123;</span></span><br><span class="line">  <span class="attr">&quot;exclude&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span><span class="punctuation">]</span><span class="punctuation">,</span></span><br><span class="line">  <span class="attr">&quot;include&quot;</span><span class="punctuation">:</span> <span class="punctuation">[</span></span><br><span class="line">    <span class="string">&quot;ancestor::*[1][contains(., &#x27;2016&#x27;)]&quot;</span><span class="punctuation">,</span></span><br><span class="line">    <span class="string">&quot;contains(., &#x27;2016&#x27;)&quot;</span></span><br><span class="line">  <span class="punctuation">]</span></span><br></pre></td></tr></table></figure><p>通过特征集合的运算，算法能够通过样本，猜测出用户选择的意图。而这样的特征集合，可以不断地添加，以满足不同页面的需要。</p><p>需要特别说明的是，特征并不需要像 demo 中使用某种特定的选择器(xpath)，由于模板执行时，可以再次为候选元素生成特征集合，对特征集合进行比较。实际上，你可以在特征集合中放入任何字符串，例如「第5元素」，「前一个字符为 answer，且值为 42」都是可以的。</p><h3 id="状态机"><a href="#状态机" class="headerlink" title="状态机"></a>状态机</h3><p>不同于往常的选取一个元素（例如 pyspider 中的选择器），data highlighter 提供了</p><ol><li>元素内文字选取</li><li>跨元素选取</li></ol><p>的功能，这使得正常的「元素选择器」不再好使，取而代之的是一种定位开始和结束的规则。描述为状态机即：<code>s0 -&gt; e0</code>。</p><p>而 data highlighter 另一种需要支持的功能为列表选取：</p><p><video controls autoplay loop src="/assets/image/screen-multi-select.mp4"></video></p><p>就不能仅仅通过 <code>s0 -&gt; e0</code> 这样开头结尾的模式进行描述了。它需要准确描述出整个列表的开头，结尾，分隔符等信息，需要通过一个类似</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">s0 -&gt; e0 -&gt; s1 -&gt; e1 -&gt; s2 -&gt; e2</span><br><span class="line">            |------|</span><br></pre></td></tr></table></figure><p>的状态机，<code>s0</code> 为整个列表的开头，<code>s1 -&gt; e1</code> 为中间循环的组，<code>e2</code> 为 整个列表的结束。</p><p>而实际中，由于某些状态可以被合并，你可能会看到类似</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">s0 -&gt; e0 -&gt; s2 -&gt; e1</span><br><span class="line">       |</span><br><span class="line">       s1</span><br></pre></td></tr></table></figure><blockquote><p>e0 和 e1 被合并了，即第一个元素的结束条件和中间元素的结束没有不同</p></blockquote><p>的状态机</p><h3 id="状态机的生成"><a href="#状态机的生成" class="headerlink" title="状态机的生成"></a>状态机的生成</h3><p>虽然状态机看起来非常复杂，但是用程序处理起来却不难。首先为每一个样本（包括列表选取）生成一条 <code>s0 -&gt; e0 -&gt; s1 -&gt; e1 -&gt; s2 -&gt; e2 -&gt; s3 -&gt; e3 ...</code> 的长链，然后尝试合并状态，然后将多个样本的链用同一规则合并。而不能合并的状态，就做个分支转移即可。</p><p>而状态能否合并，取决于它们有没有共同特征，就是这么简单。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>Data Highlighter 的算法设计，实际上是对元素特征选取的一种建模。通过设计合适的数据结构，使得多样本能够反映到模板中去。</p><p>这个算法是两年前设计的，现在看起来实际上问题蛮多的，例如：</p><ul><li>无法使用组合特征，即要求元素同时满足满足多个条件</li><li>没有设计合理的泛化机制</li><li>模板不可读</li></ul><p>等，所以，我并不打算使用这个算法。</p><p>只不过，最近些年，看到很多数据提取的公司，特别是国内的数据提取平台，还在停留在非常初级的 css selector 或者 xpath 点选生成。希望这篇文章能抛砖引玉，提供一些新的思路，为数据抽取提供更易用有效的工具。</p><p>完。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;又是好久没有写 blog 了。现在确实没有上学的时候愿意折腾了，能用钱解决的问题，就不自己动手了。但是，很久不写 blog 这事呢，其实就是因为懒 _ (:3」∠) _。&lt;/p&gt;
&lt;p&gt;这里带来的是 &lt;a href=&quot;/2014/07/how-to-extract-data</summary>
      
    
    
    
    
    <category term="html" scheme="https://binux.blog/tags/html/"/>
    
    <category term="infomation-extraction" scheme="https://binux.blog/tags/infomation-extraction/"/>
    
    <category term="wrapper-genaration" scheme="https://binux.blog/tags/wrapper-genaration/"/>
    
  </entry>
  
  <entry>
    <title>bilibili 新番承包付费意愿调查</title>
    <link href="https://binux.blog/2016/05/bilibili-pay-user-analysis/"/>
    <id>https://binux.blog/2016/05/bilibili-pay-user-analysis/</id>
    <published>2016-05-15T07:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>2014年10月1日 bilibili 正版新番承包上线，我就对 bilibili 这种自愿付费的方式感到好奇。而且经常听到「正版体验不佳」，「正版动画比起盗版，有何优势呢」的言论，那么中国用户在不插广告，不优先播放，不强制的情况下，到底愿意为「爱」付多少钱呢？</p><blockquote><p><strong>为什么 bilibili?</strong></p><p>bilibili 早期，新番都是用户上传的，可以说是典型的「盗版网站」。那么这个拥有大量用户的「盗版网站」体验应该说不差吧。</p><p>随着 bilibili 开始购买版权，现在新番实际上是正版盗版共存的模式，而 bilibili 不插前置广告（当然现在有「约不约」了），不强制付费；从体验上看，特别相对其他国内视频网站，应该是最接近「盗版」的了。</p></blockquote><h1 id="付费人数"><a href="#付费人数" class="headerlink" title="付费人数"></a>付费人数</h1><p>bilibili 新番承包人数可以非常方便的从番剧的介绍页面上获知：</p><p><img src="/assets/image/Screenshot_2016-05-15_13_41_24.png" alt="sponsor count"></p><p>但是由于动画的类型不同，热度不同，独播非独播用户（路人）成分不同，直接比较数字没有什么意义。需要首先找到一个基准来讨论播放和付费数之间的关系。</p><p>我抓取了新番承包上线以来新开播的 142 部新番（<a href="http://demo.pyspider.org/results?project=bgm_bilibili">http://demo.pyspider.org/results?project=bgm_bilibili</a>），去除话数小于10的 OAD，OVA 等，剩下 136 部。将总播放，追番人数，弹幕总数画为散点图：</p><p>![追番人数，弹幕总数 &#x2F; 总播放](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 15.29.25.png)</p><p>由图可知，弹幕总数和总播放数相关性比追番人数相关性更大（参照 <a href="https://en.wikipedia.org/wiki/Coefficient_of_determination">R^2</a>）。独家和非独家新番在弹幕参与度上相差不大，但是非独家的追番率比独家新番少了一半。难道非独家新番用户大多是非 bilibili 注册用户吗？这说不通啊，明明应该是反过来，非会员不得不到 bilibili 上看才对啊。。</p><h3 id="付费比例"><a href="#付费比例" class="headerlink" title="付费比例"></a>付费比例</h3><p>在开始写这一节的时候，我本想应该挺简单的，承包人数要么和播放数正相关，要么和活跃（弹幕数）相关，要么就和追番人数相关。但是经过了3个小时，当我尝试了：</p><ul><li>总播放数</li><li>平均每集播放数</li><li>弹幕数</li><li>收藏（追番）人数</li><li>时间</li><li>是否独家新番</li></ul><p>画了20+张图之后发现，问题并没有这么简单。很难有一个什么方法能够预测出用户的付费意愿，有很多叫好不叫座，或者叫座不叫好，导致付费比例非常分散：</p><p>![承包 &#x2F; 总播放数](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 17.55.25.png)</p><blockquote><p>图中左边是独播新番，右边为非独播</p></blockquote><p>这里面会发现一些有趣的地方：在独播和非独播中，都有一个承包比例非常高的点，分别是《电器街的漫画店》和《Fate&#x2F;stay night [Unlimited Blade Works] 第一季》，他们都是2014年10月番，正好是新番承包刚上线时的作品，可能用户对承包模式的尝鲜，或者前期宣传上的增益。</p><p>将特异点排除之后，发现不管是否独播，他们的付费比例差别不大，但是非独播的方差大得多：</p><p>![去除特异点后的 承包 &#x2F; 总播放数](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 18.00.02.png)</p><p>平均上来说，<strong>bilibili 的付费比例约为播放数的万分之 1.447，收藏人数的千分之5.373</strong>。但是这只能是整体估计，具体到单个番剧就没有意义了。</p><h3 id="用户到底为了什么付费？"><a href="#用户到底为了什么付费？" class="headerlink" title="用户到底为了什么付费？"></a>用户到底为了什么付费？</h3><p>那么，具体到每一部番剧，用户到底因为什么因素愿意付费呢？</p><p>当我将付费比例前10与付费比例后10的放在一起比较，试图找出答案的时候，我真的失败了：</p><p>![承包比例](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 21.11.35.png)</p><p>在前10中有在我看来「这什么鬼」的，在后10中也有追过的，完全搞不懂拥有更高收费比例的番剧是为什么。当然，通过加入声优，导演，制作，类型 tag 等因素，或许可能找到原因，但这样少的数据，又很容易陷入过拟合的境地（如果有兴趣，可以<a href="http://demo.pyspider.org/results?project=bgm_bilibili">下载数据</a>分析看看）。</p><h1 id="付费金额"><a href="#付费金额" class="headerlink" title="付费金额"></a>付费金额</h1><h3 id="人均承包金额"><a href="#人均承包金额" class="headerlink" title="人均承包金额"></a>人均承包金额</h3><p>虽然在 bilibili 页面中有承包商排名，但是并不知道付费的金额，仅在你承包的时候，给出你当前的排名。为了了解承包商们在这样没有强制金额的「捐献」中愿意付多少钱，我从1元开始承包，然后查看我当前的排名来获得各个区段的人数：</p><p>![承包总榜](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 21.16.24.png)</p><p>为了消除连载中，独播，类型等影响，这里选择了连载中，非独播的的 <a href="http://bangumi.bilibili.com/anime/3461">Re:Zero</a> 和已完结，独播，稍微腐女向的 <a href="http://bangumi.bilibili.com/anime/2725">K RETURN</a>。</p><p>![付费区间人数](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 18.32.14.png)</p><p>从图中可以看出：</p><ul><li>主要用户的付费金额在 5-13（不要吐槽为什么是13，手抖了！）</li><li>不同类型的番剧，承包金额的分布几乎是完全一样的</li><li>TOP 付费用户的付费金额比较高，Re:Zero 我付到 500 元，依然有 3 个比我高的（于是我放弃了）</li><li>同样付出 150 元，在 Re:Zero 中能排到 19，而在 K 中只能排到 37，还不论 K 的付费人数实际少于 Re:Zero（腐女还是有钱人多啊）</li></ul><p>那么，假如我们不考虑前 3 位的土豪，<strong>人均承包金额约为 13.08 元</strong>。因为我们并不知道土豪能为我们拉升多少身价，那，即使我们现在假设排名前三的土豪均承包五千块，人均承包金额也不过18元。为了简化，我们取20块好了。因为选取了两部因素差异蛮大的动画，得知不同因素对承包金额的分布影响不大，这个人均承包金额是可以套用到不同番剧上的。</p><h3 id="承包收入"><a href="#承包收入" class="headerlink" title="承包收入"></a>承包收入</h3><p>那我们算一下，bilibili 通过新番承包，到底能赚多少钱呢？因为承包人数是公开的，乘以估计的人均20块的话，bilibili 承包收入收入排行：</p><p>![承包收入排行](&#x2F;assets&#x2F;image&#x2F;Screenshot 2016-05-15 18.55.03.png)</p><p>根据网上的传言，每集非独播新番版权价格大约是5万，独播更贵。那么好，我们统统算1万一集吧（对，就是这么任性）！那么也就 《Fate&#x2F;stay night [Unlimited Blade Works] 第一季》 和 《电器街的漫画店》 实现了盈利。记得我们前面说过的付费比例异常吗？对，就是这两部「盈利」了的番剧。</p><p>从整体来看，bilibili 通过承包总收入为 288.7 万，平均每部番剧的承包收入是 21388 元，不打折的话，一集都买不起啊！</p><h1 id="我想说什么"><a href="#我想说什么" class="headerlink" title="我想说什么"></a>我想说什么</h1><p>经常有人会用「正版体验不佳」作为盗版的理由，<strong>说得好像正版体验一样了就会付费了似的</strong>。bilibili 同时有提供正版和盗版内容，正版有比盗版体验差吗？难道正版看得人就少了吗？好，就算确实看正版的人少了，我们不看绝对值，那这寒酸的千分之5.373的付费比例是怎么回事？什么「正版体验不佳」啊，「要付钱当然体验不佳」啦。</p><p>另外一个常见的理由是「学生党，没有钱」，人均 20 块太贵出不起。请回过头看看追番人数，要是每个人出<strong>一块钱</strong>，那也要比现在这千分之5.373，人均20块的总收入高啊！<strong>一块钱</strong>都出不起吗？这可是<strong>一季</strong>动画，而不是一集让你出一块钱啊！看动画都是因为爱，而这份爱，连一块钱都不值吗？</p><p><img src="/assets/image/ai.jpg" alt="爱"></p><p>bilibili 不想通过广告那样半强制地收回那么一点点版权费，然而看起来这「爱」并不畅销。<strong>所以，我弱弱地提议，各位有爱的小伙伴，在看完一季动画后（是的，不喜欢可以不承包），从微信红包（是的，不用银行卡）中拿出那么一块钱（是的，最低承包不是5块，是可以改的），承包一下你喜欢的动画吧。</strong>。希望在「劣币驱逐良币」之前，良币不会先自己饿死吧。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;2014年10月1日 bilibili 正版新番承包上线，我就对 bilibili 这种自愿付费的方式感到好奇。而且经常听到「正版体验不佳」，「正版动画比起盗版，有何优势呢」的言论，那么中国用户在不插广告，不优先播放，不强制的情况下，到底愿意为「爱」付多少钱呢？&lt;/p&gt;
&lt;</summary>
      
    
    
    
    
    <category term="bilibili" scheme="https://binux.blog/tags/bilibili/"/>
    
    <category term="ACG" scheme="https://binux.blog/tags/ACG/"/>
    
  </entry>
  
  <entry>
    <title>demo.pyspider.org 部署经验</title>
    <link href="https://binux.blog/2016/05/deployment-of-demopyspiderorg/"/>
    <id>https://binux.blog/2016/05/deployment-of-demopyspiderorg/</id>
    <published>2016-05-14T07:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>经常有人会问 <a href="https://github.com/binux/pyspider">pyspider</a> 怎么进行分布式部署，这里以 <a href="http://demo.pyspider.org/">demo.pyspider.org</a> 的实际部署经验做一个例子。</p><p>因为 <a href="https://github.com/binux/pyspider">pyspider</a> 支持分布式部署，为了验证也好，为了省钱多蹭 CPU 也好, <a href="http://demo.pyspider.org/">demo.pyspider.org</a> 通过 docker 部署在同一机房的 3 台 VPS 上，VPS 间有内网传输（实际通过 <a href="http://www.tinc-vpn.org/">tinc</a>）。</p><p>使用 docker 的原因是实际上 pyspider 能够运行任何 python 脚本，至少需要 docker 环境逃逸。</p><h1 id="数据库-amp-消息队列"><a href="#数据库-amp-消息队列" class="headerlink" title="数据库 &amp; 消息队列"></a>数据库 &amp; 消息队列</h1><p>demo.pyspider.org 的**数据库为 <a href="http://www.postgresql.org/">PostgreSQL</a><strong>，理由是测试目的，磁盘占用和性能的折中。</strong>消息队列为 <a href="http://redis.io/">Redis</a>**，因为部署简单。</p><p>它们也是跑在 docker 中的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">docker run --name postgres -v /data/postgres/:/var/lib/postgresql/data -d -p <span class="variable">$LOCAL_IP</span>:5432:5432 -e POSTGRES_PASSWORD=<span class="string">&quot;&quot;</span> postgres</span><br><span class="line">docker run --name redis -d -p  <span class="variable">$LOCAL_IP</span>:6379:6379 redis</span><br></pre></td></tr></table></figure><p>由于前面说过，机器间有内网，通过绑定内网 IP，没有做鉴权（反正 demo 会泄露）。</p><h1 id="scheduler"><a href="#scheduler" class="headerlink" title="scheduler"></a>scheduler</h1><p>由于 scheduler 只能运行一个，并且需要进行大量的数据库操作，它与上面的数据库和消息队列部署在一台单独的机器上。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">docker run --name scheduler -d -p <span class="variable">$LOCAL_IP</span>:23333:23333 --restart=always binux/pyspider \</span><br><span class="line"> --taskdb <span class="string">&quot;sqlalchemy+postgresql+taskdb://binux@10.21.0.7/taskdb&quot;</span> \</span><br><span class="line"> --resultdb <span class="string">&quot;sqlalchemy+postgresql+resultdb://binux@10.21.0.7/resultdb&quot;</span> \</span><br><span class="line"> --projectdb <span class="string">&quot;sqlalchemy+postgresql+projectdb://binux@10.21.0.7/projectdb&quot;</span> \</span><br><span class="line"> --message-queue <span class="string">&quot;redis://10.21.0.7:6379/1&quot;</span> \</span><br><span class="line"> scheduler --inqueue-limit 5000 --delete-time 43200</span><br></pre></td></tr></table></figure><h1 id="其他组件"><a href="#其他组件" class="headerlink" title="其他组件"></a>其他组件</h1><p>所有其他的组件（fetcher, processor, result_worker）在剩余的两台 VPS 上以相同的配置启动。他们都是通过 docker-compose 管理的</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><span class="line"><span class="attr">phantomjs:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;binux/pyspider:latest&#x27;</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">phantomjs</span></span><br><span class="line">  <span class="attr">cpu_shares:</span> <span class="number">512</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;EXCLUDE_PORTS=5000,23333,24444&#x27;</span></span><br><span class="line">  <span class="attr">expose:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;25555&#x27;</span></span><br><span class="line">  <span class="attr">mem_limit:</span> <span class="string">512m</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">phantomjs-lb:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;dockercloud/haproxy:latest&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">phantomjs</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">fetcher:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;binux/pyspider:latest&#x27;</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&#x27;--message-queue &quot;redis://10.21.0.7:6379/1&quot; --phantomjs-proxy &quot;phantomjs:80&quot; fetcher --xmlrpc&#x27;</span></span><br><span class="line">  <span class="attr">cpu_shares:</span> <span class="number">512</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;EXCLUDE_PORTS=5000,25555,23333&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;phantomjs-lb:phantomjs&#x27;</span></span><br><span class="line">  <span class="attr">mem_limit:</span> <span class="string">128m</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">fetcher-lb:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;dockercloud/haproxy:latest&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">fetcher</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">processor:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;binux/pyspider:latest&#x27;</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&#x27;--projectdb &quot;sqlalchemy+postgresql+projectdb://binux@10.21.0.7/projectdb&quot; --message-queue &quot;redis://10.21.0.7:6379/1&quot; processor&#x27;</span></span><br><span class="line">  <span class="attr">cpu_shares:</span> <span class="number">512</span></span><br><span class="line">  <span class="attr">mem_limit:</span> <span class="string">256m</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">result-worker:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;binux/pyspider:latest&#x27;</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&#x27;--taskdb &quot;sqlalchemy+postgresql+taskdb://binux@10.21.0.7/taskdb&quot;  --projectdb &quot;sqlalchemy+postgresql+projectdb://binux@10.21.0.7/projectdb&quot; --resultdb &quot;sqlalchemy+postgresql+resultdb://binux@10.21.0.7/resultdb&quot; --message-queue &quot;redis://10.21.0.7:6379/1&quot; result_worker&#x27;</span></span><br><span class="line">  <span class="attr">cpu_shares:</span> <span class="number">512</span></span><br><span class="line">  <span class="attr">mem_limit:</span> <span class="string">256m</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">webui:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;binux/pyspider:latest&#x27;</span></span><br><span class="line">  <span class="attr">command:</span> <span class="string">&#x27;--taskdb &quot;sqlalchemy+postgresql+taskdb://binux@10.21.0.7/taskdb&quot;  --projectdb &quot;sqlalchemy+postgresql+projectdb://binux@10.21.0.7/projectdb&quot; --resultdb &quot;sqlalchemy+postgresql+resultdb://binux@10.21.0.7/resultdb&quot; --message-queue &quot;redis://10.21.0.7:6379/1&quot; webui --max-rate 0.2 --max-burst 3 --scheduler-rpc &quot;http://o4.i.binux.me:23333/&quot; --fetcher-rpc &quot;http://fetcher/&quot;&#x27;</span></span><br><span class="line"></span><br><span class="line">  <span class="attr">cpu_shares:</span> <span class="number">512</span></span><br><span class="line">  <span class="attr">environment:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;EXCLUDE_PORTS=24444,25555,23333&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;fetcher-lb:fetcher&#x27;</span></span><br><span class="line">  <span class="attr">mem_limit:</span> <span class="string">256m</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line"><span class="attr">webui-lb:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;dockercloud/haproxy:latest&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">webui</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br><span class="line">  </span><br><span class="line"><span class="attr">nginx:</span></span><br><span class="line">  <span class="attr">image:</span> <span class="string">&#x27;nginx&#x27;</span></span><br><span class="line">  <span class="attr">links:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;webui-lb:HAPROXY&#x27;</span></span><br><span class="line">  <span class="attr">ports:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">&#x27;0.0.0.0:80:80&#x27;</span></span><br><span class="line">  <span class="attr">volumes:</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/home/binux/nfs/profile/nginx/nginx.conf:/etc/nginx/nginx.conf</span></span><br><span class="line">    <span class="bullet">-</span> <span class="string">/home/binux/nfs/profile/nginx/conf.d/:/etc/nginx/conf.d/</span></span><br><span class="line">  <span class="attr">restart:</span> <span class="string">always</span></span><br></pre></td></tr></table></figure><p>然后通过 <code>docker-compose scale phantomjs=2 processor=2 webui=4</code> 指定启动两个 phantomjs 进程，两个 processor 进程，4个 webui 进程。</p><h4 id="phantomjs"><a href="#phantomjs" class="headerlink" title="phantomjs"></a>phantomjs</h4><p>由于 phantomjs 有内存泄露问题，限制下内存就好了。<code>EXCLUDE_PORTS</code> 是为了下面的 haproxy 能够正确的均衡负载正确端口。</p><h4 id="phantomjs-lb"><a href="#phantomjs-lb" class="headerlink" title="phantomjs-lb"></a>phantomjs-lb</h4><p>通过 <a href="https://hub.docker.com/r/dockercloud/haproxy/">haproxy</a> 自动负载均衡，只要将服务链接上去，就会将请求分发到不定多个 phantomjs 实例上，同时只暴露一个对外服务端口。</p><h4 id="fetcher"><a href="#fetcher" class="headerlink" title="fetcher"></a>fetcher</h4><p>链接 <code>phantomjs-lb:phantomjs</code>，注意这里的 <code>--phantomjs-proxy &quot;phantomjs:80&quot;</code></p><p>由于 fetcher 是异步 http 请求，如果没有发生堵塞，单个 fetcher 一般就足够了。</p><h4 id="fetcher-lb"><a href="#fetcher-lb" class="headerlink" title="fetcher-lb"></a>fetcher-lb</h4><p>同 phantomjs-lb</p><h4 id="processor"><a href="#processor" class="headerlink" title="processor"></a>processor</h4><p>processor 为最消耗 CPU 的组件，建议根据 CPU 的数量部署 +1&#x2F;2 个。</p><h4 id="result-worker"><a href="#result-worker" class="headerlink" title="result-worker"></a>result-worker</h4><p>默认的 result-worker 只是在写数据库，除非发生堵塞，或者你重载了 result_worker，一个就够。</p><h4 id="webui"><a href="#webui" class="headerlink" title="webui"></a>webui</h4><p>首先，webui 为了安全性，限制了最大抓取速率 <code>--max-rate 0.2 --max-burst 3</code>。</p><p>然后通过实际的 fetcher 进行抓取 <code>--fetcher-rpc &quot;http://fetcher/&quot;</code> 而不是 webui 自己发起请求，最大程度模拟环境（IP，库版本），因为以前遇到过调试的时候没问题，跑起来失败，然后在调试器复现又没法复现的问题。fetcher-rpc 可以不用，这样的会 webui 会自己直接发起请求。</p><p>因为 demo.pyspider.org 主要就是提供通过页面来尝试 pyspider, 这里的负载较大，而且实现上是同步的，任何脚本执行，抓取都是堵塞了，多一些 webui 会比较好。</p><h4 id="webui-lb"><a href="#webui-lb" class="headerlink" title="webui-lb"></a>webui-lb</h4><p>同 phantpmjs-lb</p><h4 id="nginx"><a href="#nginx" class="headerlink" title="nginx"></a>nginx</h4><p>这里做了一些前端缓存</p><h4 id="其他"><a href="#其他" class="headerlink" title="其他"></a>其他</h4><p>因为懒得管，每小时我会重启除了 scheduler 以外的其他组件（反正会重试）。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;经常有人会问 &lt;a href=&quot;https://github.com/binux/pyspider&quot;&gt;pyspider&lt;/a&gt; 怎么进行分布式部署，这里以 &lt;a href=&quot;http://demo.pyspider.org/&quot;&gt;demo.pyspider.org&lt;/a&gt; 的</summary>
      
    
    
    
    
    <category term="pyspider" scheme="https://binux.blog/tags/pyspider/"/>
    
    <category term="deployment" scheme="https://binux.blog/tags/deployment/"/>
    
  </entry>
  
  <entry>
    <title>足兆叉虫的2015</title>
    <link href="https://binux.blog/2015/12/uk2/"/>
    <id>https://binux.blog/2015/12/uk2/</id>
    <published>2015-12-31T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>我是从来不记日子的，这导致我也不知道有些事情是2015年发生的，还是2014年发生的，亦或只是我的臆想。即便如此，2015年也是变化的一年。</p><p>跳槽，工资没涨…… 到这里居然和2013年是一样的，但是当我在2015写下这篇日志的时候，国内已经2016。</p><p>说来惭愧，这一年除了一月写了几篇教程之后，不但 blog 落下了，开源也没有做多少。看着 pyspider 的 star 数蹭蹭涨到 5813，但是并没有太多精力去更新。希望在 2016 年能有时间把 slime 模式的坑填了吧。</p><p>其他的项目也就在年末的时候又重新玩了一把 WebRTC，基于的 <a href="https://webtorrent.io/">WebTorrent</a> 经过一年的开发，已经成熟了很多，feross 在 javascript 上从 tracker 到 BT 协议都实现了一遍，比起我那时山寨的好了非常多，虽然 hybrid 模式还有很多问题。。。对了 2015 年参与过 technical review 的 <a href="https://www.packtpub.com/web-development/learning-webrtc">Learning WebRTC</a> 也出版了，算是一次挺有趣的经历吧。</p><p>8月到英国之后，就是各种适应，加上新公司的蜜月期，一门心思放在了公司的项目上。在新公司才算是第一次接触到了机器学习，给我带来了很多新的思路，有种能成的感觉吧。</p><p>希望2016年能更有趣吧。</p><h2 id="英国（二）"><a href="#英国（二）" class="headerlink" title="英国（二）"></a>英国（二）</h2><p>然后说一些「关于英国生活」类似的东西吧，想到什么写什么</p><h3 id="衣食住行"><a href="#衣食住行" class="headerlink" title="衣食住行"></a>衣食住行</h3><ul><li>夏天不热，这个冬天不冷</li><li>冬天是雨季，几乎一半时间在下雨，但是从来没有在上下班的时候下</li><li>英国不负「难吃国」之名，只要是英文店名的地方，那真是难吃 + 贵</li><li>中午的饭点是1-2点，晚餐饭点是8-9点</li><li>一个很大问题是，看菜单很多时候不知道是什么东西，查字典也没用</li><li>一盒 200g 的毛豆都要卖20-30RMB，而且还被他们视为高贵的健康食品</li><li>有很多中国人开的中餐馆和日式便当，这是唯一能吃的东西（除了 KFC）</li><li>超市的肉类品种和部位很不同，炒出来很老，我用了3个月才想出来怎么吃</li><li>鸡翅鸡腿比鸡胸便宜，只要10RMB&#x2F;斤</li><li>肉比蔬菜便宜</li><li>住非常贵，北京的7-8倍</li><li>行非常贵，北京的5-10倍</li><li>伦敦很小，和北京比起来</li></ul><h3 id="公司"><a href="#公司" class="headerlink" title="公司"></a>公司</h3><ul><li>公司现在有40+个人，但是有15种国籍，22+种语言</li><li>有4个华裔同事，但是任意两者之间只能用英语交流（除英语外会的语言分别是普通话，粤语，日语，马来语，德语）</li><li>没有印度人</li><li>一年25天年假，8天法定假日，没有年终奖</li><li>不加班的主要原因是没有晚餐，肚子饿</li><li>公司以外听不懂别人说什么 &#x3D;_&#x3D;</li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我是从来不记日子的，这导致我也不知道有些事情是2015年发生的，还是2014年发生的，亦或只是我的臆想。即便如此，2015年也是变化的一年。&lt;/p&gt;
&lt;p&gt;跳槽，工资没涨…… 到这里居然和2013年是一样的，但是当我在2015写下这篇日志的时候，国内已经2016。&lt;/p&gt;
</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>英国</title>
    <link href="https://binux.blog/2015/07/uk/"/>
    <id>https://binux.blog/2015/07/uk/</id>
    <published>2015-07-21T07:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>半年没有更新 blog 了，<del>其实我在憋(wan)个(W)大(O)招(W)</del>。一年半以前，我说过<a href="http://blog.binux.me/2013/12/2013/">「想学日语，想出国」</a>，虽然这一年半也是没有干劲地随随便便过的，但是至少出国了。</p><p>目的地英国，工作，8月初。</p><p>要说经历，其实简单到爆。</p><ol><li>投简历（依旧是只投一家）</li><li>视频面试（用我8年没用过的蹩脚英语）</li><li>考雅思（而且只要4分，我只做了套剑9就去了）</li><li>对方办 <a href="https://www.gov.uk/tier-2-general/eligibility">certificates of sponsorship</a>（虽然每月有名额限制，按照打分排，但是以往的数据，只要满足条件，名额都够。）</li><li>办签证（不像旅游签证，不用行程单，不用资产证明，有 COS 就 ok）</li><li>买机票</li><li>over</li></ol><p>工资没涨，物价大涨，难吃，加上烂英语，瞬间感觉生活甚是艰辛。。。不过， there is always a way，就当作一次挑战吧。</p><p>就酱</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;半年没有更新 blog 了，&lt;del&gt;其实我在憋(wan)个(W)大(O)招(W)&lt;/del&gt;。一年半以前，我说过&lt;a href=&quot;http://blog.binux.me/2013/12/2013/&quot;&gt;「想学日语，想出国」&lt;/a&gt;，虽然这一年半也是没有干劲地随随便便过的，</summary>
      
    
    
    
    
  </entry>
  
  <entry>
    <title>pyspider 爬虫教程（三）：使用 PhantomJS 渲染带 JS 的页面</title>
    <link href="https://binux.blog/2015/01/pyspider-tutorial-level-3-render-with-phantomjs/"/>
    <id>https://binux.blog/2015/01/pyspider-tutorial-level-3-render-with-phantomjs/</id>
    <published>2015-01-10T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>英文原文：<a href="http://docs.pyspider.org/en/latest/tutorial/Render-with-PhantomJS/">http://docs.pyspider.org/en/latest/tutorial/Render-with-PhantomJS/</a></p><p>在上两篇教程中，我们学习了怎么从 HTML 中提取信息，也学习了怎么处理一些请求复杂的页面。但是有一些页面，它实在太复杂了，无论是分析 API 请求的地址，还是渲染时进行了加密，让直接抓取请求非常麻烦。这时候就是 <a href="http://phantomjs.org/">PhantomJS</a> 大显身手的时候了。</p><p>在使用 <a href="http://phantomjs.org/">PhantomJS</a> 之前，你需要安装它（<a href="http://phantomjs.org/download.html">安装文档</a>）。当你安装了之后，在运行 <code>all</code> 模式的 pyspider 时就会自动启用了。当然，你也可以在 <a href="http://demo.pyspider.org/">demo.pyspider.org</a> 上尝试。</p><h2 id="使用-PhantomJS"><a href="#使用-PhantomJS" class="headerlink" title="使用 PhantomJS"></a>使用 PhantomJS</h2><p>当 pyspider 连上 PhantomJS 代理后，你就能通过在 <code>self.crawl</code> 中添加 <code>fetch_type=&#39;js&#39;</code> 的参数，开启使用 PhantomJS 抓取。例如，在教程二中，我们尝试抓取的 <a href="http://movie.douban.com/explore">http://movie.douban.com/explore</a> 就可以通过 PhantomJS 直接抓取：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Handler</span>(<span class="title class_ inherited__">BaseHandler</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">        self.crawl(<span class="string">&#x27;http://movie.douban.com/explore&#x27;</span>,</span><br><span class="line">                   fetch_type=<span class="string">&#x27;js&#x27;</span>, callback=self.phantomjs_parser)</span><br><span class="line">    </span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">phantomjs_parser</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">return</span> [&#123;</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: <span class="string">&quot;&quot;</span>.join(</span><br><span class="line">                s <span class="keyword">for</span> s <span class="keyword">in</span> x(<span class="string">&#x27;p&#x27;</span>).contents() <span class="keyword">if</span> <span class="built_in">isinstance</span>(s, basestring)</span><br><span class="line">            ).strip(),</span><br><span class="line">            <span class="string">&quot;rate&quot;</span>: x(<span class="string">&#x27;p strong&#x27;</span>).text(),</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: x.attr.href,</span><br><span class="line">        &#125; <span class="keyword">for</span> x <span class="keyword">in</span> response.doc(<span class="string">&#x27;a.item&#x27;</span>).items()]</span><br></pre></td></tr></table></figure><blockquote><ul><li>我在这里使用了一些 PyQuery 的 API，你可以在 <a href="https://pythonhosted.org/pyquery/api.html">PyQuery complete API</a> 获得完整的 API 手册。</li></ul></blockquote><h2 id="在页面上执行自定义脚本"><a href="#在页面上执行自定义脚本" class="headerlink" title="在页面上执行自定义脚本"></a>在页面上执行自定义脚本</h2><p>你会发现，在上面我们使用 <a href="http://phantomjs.org/">PhantomJS</a> 抓取的豆瓣热门电影只有 20 条。当你点击『加载更多』时，能获得更多的热门电影。为了获得更多的电影，我们可以使用 <code>self.crawl</code> 的 <code>js_script</code> 参数，在页面上执行一段脚本，点击加载更多：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">    self.crawl(<span class="string">&#x27;http://movie.douban.com/explore#more&#x27;</span>,</span><br><span class="line">               fetch_type=<span class="string">&#x27;js&#x27;</span>, js_script=<span class="string">&quot;&quot;&quot;</span></span><br><span class="line"><span class="string">               function() &#123;</span></span><br><span class="line"><span class="string">                 setTimeout(&quot;$(&#x27;.more&#x27;).click()&quot;, 1000);</span></span><br><span class="line"><span class="string">               &#125;&quot;&quot;&quot;</span>, callback=self.phantomjs_parser)</span><br></pre></td></tr></table></figure><blockquote><ul><li>这个脚本默认在页面加载结束后执行，你可以通过 <code>js_run_at</code> <a href="http://docs.pyspider.org/en/latest//apis/self.crawl/#enable-javascript-fetcher-need-support-by-fetcher">参数</a> 修改这个行为</li><li>由于是 AJAX 异步加载的，在页面加载完成时，第一页的电影可能还没有加载完，所以我们用 <code>setTimeout</code> 延迟 1 秒执行。</li><li>你可以间隔一定时间，多次点击，这样可以加载更多页。</li><li>由于相同 URL （实际是相同 taskid） 的任务会被去重，所以这里为 URL 加了一个 <code>#more</code></li></ul></blockquote><p>上面两个例子，都可以在 <a href="http://demo.pyspider.org/debug/tutorial_douban_explore">http://demo.pyspider.org/debug/tutorial_douban_explore</a> 中找到。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;英文原文：&lt;a href=&quot;http://docs.pyspider.org/en/latest/tutorial/Render-with-PhantomJS/&quot;&gt;http://docs.pyspider.org/en/latest/tutorial/Render-with</summary>
      
    
    
    
    
    <category term="python" scheme="https://binux.blog/tags/python/"/>
    
    <category term="pyspider" scheme="https://binux.blog/tags/pyspider/"/>
    
  </entry>
  
  <entry>
    <title>pyspider 爬虫教程（二）：AJAX 和 HTTP</title>
    <link href="https://binux.blog/2015/01/pyspider-tutorial-level-2-ajax-and-more-http/"/>
    <id>https://binux.blog/2015/01/pyspider-tutorial-level-2-ajax-and-more-http/</id>
    <published>2015-01-09T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>在上一篇教程中，我们使用 <code>self.crawl</code> API 抓取豆瓣电影的 HTML 内容，并使用 CSS 选择器解析了一些内容。不过，现在的网站通过使用 <a href="http://www.w3school.com.cn/ajax/ajax_intro.asp">AJAX</a> 等技术，在你与服务器交互的同时，不用重新加载整个页面。但是，这些交互手段，让抓取变得稍微难了一些：你会发现，这些网页在抓回来后，和浏览器中的并不相同。你需要的信息并不在返回 HTML 代码中。</p><p>在这一篇教程中，我们会讨论这些技术 和 抓取他们的方法。（英文版：<a href="http://docs.pyspider.org/en/latest/tutorial/AJAX-and-more-HTTP/">AJAX-and-more-HTTP</a>）</p><h2 id="AJAX"><a href="#AJAX" class="headerlink" title="AJAX"></a>AJAX</h2><p><a href="http://www.w3school.com.cn/ajax/ajax_intro.asp">AJAX</a> 是 Asynchronous JavaScript and XML（异步的 JavaScript 和 XML）的缩写。AJAX 通过使用原有的 web 标准组件，实现了在不重新加载整个页面的情况下，与服务器进行数据交互。例如在新浪微博中，你可以展开一条微博的评论，而不需要重新加载，或者打开一个新的页面。但是这些内容并不是一开始就在页面中的（这样页面就太大了），而是在你点击的时候被加载进来的。这就导致了你抓取这个页面的时候，并不能获得这些评论信息（因为你没有『展开』）。</p><p><a href="http://www.w3school.com.cn/ajax/ajax_intro.asp">AJAX</a> 的一种常见用法是使用 <a href="http://www.w3school.com.cn/ajax/ajax_intro.asp">AJAX</a> 加载 <a href="http://www.w3school.com.cn/json/">JSON</a> 数据，然后在浏览器端渲染。如果能直接抓取到 <a href="http://www.w3school.com.cn/json/">JSON</a> 数据，会比 HTML 更容易解析。</p><p>当一个网站使用了 AJAX 的时候，除了用 pyspider 抓取到的页面和浏览器看到的不同以外。你在浏览器中打开这样的页面，或者点击『展开』的时候，常常会看到『加载中』或者类似的图标&#x2F;动画。例如，当你尝试抓取：<a href="http://movie.douban.com/explore">http://movie.douban.com/explore</a></p><p><img src="/assets/image/douban_explore.png" alt="douban explore"></p><p>你会发现电影是『载入中…』</p><h3 id="找到真实的请求"><a href="#找到真实的请求" class="headerlink" title="找到真实的请求"></a>找到真实的请求</h3><p>由于 AJAX 实际上也是通过 HTTP 传输数据的，所以我们可以通过 <a href="https://developer.chrome.com/devtools">Chrome Developer Tools</a> 找到真实的请求，直接发起真实请求的抓取就可以获得数据了。</p><ol><li>打开一个新窗口</li><li>按 <code>Ctrl</code>+<code>Shift</code>+<code>I</code> (在 Mac 上请按 <code>Cmd</code>+<code>Opt</code>+<code>I</code>) 打开开发者工具。</li><li>切换到网络（ Netwotk 面板）</li><li>在窗口中打开 <a href="http://movie.douban.com/explore">http://movie.douban.com/explore</a></li></ol><p>在页面加载的过程中，你会在面板中看到所有的资源请求。</p><p><img src="/assets/image/douban_explore_network_panel.png" alt="douban explore network panel"></p><p>AJAX 一般是通过 <a href="http://www.w3school.com.cn/ajax/ajax_xmlhttprequest_create.asp">XMLHttpRequest</a> 对象接口发送请求的，XMLHttpRequest 一般被缩写为 XHR。点击网络面板上漏斗形的过滤按钮，过滤出 XHR 请求。挨个查看每个请求，通过访问路径和预览，找到包含信息的请求：<a href="http://movie.douban.com/j/search_subjects?type=movie&tag=%E7%83%AD%E9%97%A8&sort=recommend&page_limit=20&page_start=0">http://movie.douban.com/j/search_subjects?type&#x3D;movie&amp;tag&#x3D;%E7%83%AD%E9%97%A8&amp;sort&#x3D;recommend&amp;page_limit&#x3D;20&amp;page_start&#x3D;0</a></p><p><img src="/assets/image/douban_explore_xhr_preview.png" alt="douban explore xhr preview"></p><p>在豆瓣这个例子中，XHR 请求并不多，可以挨个查看来确认。但在 XHR 请求较多的时候，可能需要结合触发动作的时间，请求的路径等信息帮助在大量的请求中找到包含信息的关键请求。这需要抓取或者前端的相关经验。所以，有一个我一直在提的观点，学习抓取的最好方法是：学会写网站。</p><p>现在可以在新窗口中打开 <a href="http://movie.douban.com/j/search_subjects?type=movie&tag=%E7%83%AD%E9%97%A8&sort=recommend&page_limit=20&page_start=0">http://movie.douban.com/j/search_subjects?type&#x3D;movie&amp;tag&#x3D;%E7%83%AD%E9%97%A8&amp;sort&#x3D;recommend&amp;page_limit&#x3D;20&amp;page_start&#x3D;0</a>，你会看到包含电影数据的 <a href="http://www.w3school.com.cn/json/">JSON</a> 原始数据。推荐安装 <a href="https://chrome.google.com/webstore/detail/jsonview/chklaanhfefbnpoihckbnefhakgolnmc">JSONView</a>（<a href="http://jsonview.com/">Firfox版</a>）插件，这样可以看到更好看的 JSON 格式，展开折叠列等功能。然后，我们根据 <a href="http://www.w3school.com.cn/json/">JSON</a> 数据，编写一个提取电影名和评分的脚本：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">class</span> <span class="title class_">Handler</span>(<span class="title class_ inherited__">BaseHandler</span>):</span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">        self.crawl(<span class="string">&#x27;http://movie.douban.com/j/search_subjects?type=movie&amp;tag=%E7%83%AD%E9%97%A8&amp;sort=recommend&amp;page_limit=20&amp;page_start=0&#x27;</span>,</span><br><span class="line">                   callback=self.json_parser)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">json_parser</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">return</span> [&#123;</span><br><span class="line">            <span class="string">&quot;title&quot;</span>: x[<span class="string">&#x27;title&#x27;</span>],</span><br><span class="line">            <span class="string">&quot;rate&quot;</span>: x[<span class="string">&#x27;rate&#x27;</span>],</span><br><span class="line">            <span class="string">&quot;url&quot;</span>: x[<span class="string">&#x27;url&#x27;</span>]</span><br><span class="line">        &#125; <span class="keyword">for</span> x <span class="keyword">in</span> response.json[<span class="string">&#x27;subjects&#x27;</span>]]</span><br></pre></td></tr></table></figure><blockquote><ul><li>你可以使用 <code>response.json</code> 将结果转为一个 python 的 <code>dict</code> 对象</li></ul></blockquote><p>你可以在 <a href="http://demo.pyspider.org/debug/tutorial_douban_explore">http://demo.pyspider.org/debug/tutorial_douban_explore</a> 获得完整的代码，并进行调试。脚本中还有一个使用 <a href="http://phantomjs.org/">PhantomJS</a> 渲染的提取版本，将会在下一篇教程中介绍。</p><h2 id="HTTP"><a href="#HTTP" class="headerlink" title="HTTP"></a>HTTP</h2><p><a href="http://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">HTTP</a> 是用来传输网页内容的协议。在前面的教程中，我们已经通过 <code>self.crawl</code> 接口提交了 URL 进行了抓取。这些抓取就是通过 HTTP 协议传输的。</p><p>在抓取过程中，你可能会遇到类似 <code>403 Forbidden</code>，或者需要登录的情况，这时候你就需要正确的 HTTP 参数进行抓取了。</p><p>一个典型的 HTTP 请求包如下，这个请求是发往 <a href="http://example.com/">http://example.com/</a> 的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">GET / HTTP/1.1</span><br><span class="line">Host: example.com</span><br><span class="line">Connection: keep-alive</span><br><span class="line">Cache-Control: max-age=0</span><br><span class="line">Accept: text/html,application/xhtml+xml,application/xml;q=0.9,image/webp,*/*;q=0.8</span><br><span class="line">User-Agent: Mozilla/5.0 (Macintosh; Intel Mac OS X 10_10_1) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/40.0.2214.45 Safari/537.36</span><br><span class="line">Referer: http://en.wikipedia.org/wiki/Example.com</span><br><span class="line">Accept-Encoding: gzip, deflate, sdch</span><br><span class="line">Accept-Language: zh-CN,zh;q=0.8</span><br><span class="line">If-None-Match: <span class="string">&quot;359670651&quot;</span></span><br><span class="line">If-Modified-Since: Fri, 09 Aug 2013 23:54:35 GMT</span><br></pre></td></tr></table></figure><blockquote><ul><li>请求的第一行包含 <code>method</code>, <code>path</code> 和 HTTP 协议的版本信息</li><li>余下的行被称为 header，是以 <code>key: value</code> 的形式呈现的</li><li>如果是 POST 请求，在请求结尾可能还会有 <code>body</code> 内容</li></ul></blockquote><p>你可以通过前面用过的 <a href="https://developer.chrome.com/devtools">Chrome Developer Tools</a> 工具查看到这些信息：</p><p><img src="/assets/image/request-headers.png" alt="request headers"></p><p>在大多数时候，使用正确的 <code>method</code>, <code>path</code>, <code>headers</code> 和 <code>body</code> 总是能抓取到你需要的信息的。</p><h3 id="HTTP-Method"><a href="#HTTP-Method" class="headerlink" title="HTTP Method"></a>HTTP Method</h3><p><a href="http://www.w3school.com.cn/tags/html_ref_httpmethods.asp">HTTP Method</a> 告诉服务器对 URL 资源期望进行的操作。例如在打开一个 URL 的时候使用的是 GET 方式，而在提交数据的时候一般使用 POST。</p><p>TODO： need example here</p><h3 id="HTTP-Headers"><a href="#HTTP-Headers" class="headerlink" title="HTTP Headers"></a>HTTP Headers</h3><p>HTTP Headers 是请求所带的一个参数列表，你可以在 <a href="http://en.wikipedia.org/wiki/List_of_HTTP_header_fields">这里</a> 找到完整的常用 Headers 列表。一些常用的需要注意的有：</p><h4 id="User-Agent"><a href="#User-Agent" class="headerlink" title="User-Agent"></a>User-Agent</h4><p>UA 是标识你使用的浏览器，或抓取程序的一段字符串。pyspider 使用的默认 UA 是 <code>pyspider/VERSION (+http://pyspider.org/)</code>。网站常用这个字符串来区分用户的操作系统和浏览器，以及判断对方是否是爬虫。所以在抓取的时候，常常会对 UA 进行伪装。</p><p>在 pyspider 中，你可以通过 <code>self.crawl(URL, headers=&#123;&#39;User-Agent&#39;: &#39;pyspider&#39;&#125;)</code>，或者是 <code>crawl_config = &#123;&#39;headers&#39;: &#123;&#39;User-Agent&#39;: &#39;xxxx&#39;&#125;&#125;</code> 来指定脚本级别的 UA。详细请查看 <a href="http://docs.pyspider.org/en/latest/apis/self.crawl/#fetch">API 文档</a>。</p><h4 id="Referer"><a href="#Referer" class="headerlink" title="Referer"></a>Referer</h4><p>Referer 用于告诉服务器，你访问的上一个网页是什么。常常被用于防盗链，在抓取图片的时候可能会用到。</p><h4 id="X-Requested-With"><a href="#X-Requested-With" class="headerlink" title="X-Requested-With"></a>X-Requested-With</h4><p>当使用 XHR 发送 AJAX 请求时会带上的 Header，常被用于判断是不是 AJAX 请求。例如在 <a href="http://bbs.byr.cn/">北邮人论坛</a> 中，你需要：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">    self.crawl(<span class="string">&#x27;http://bbs.byr.cn/board/Python&#x27;</span>,</span><br><span class="line">               headers=&#123;<span class="string">&#x27;X-Requested-With&#x27;</span>: <span class="string">&#x27;XMLHttpRequest&#x27;</span>&#125;,</span><br><span class="line">               callback=self.index_page)</span><br></pre></td></tr></table></figure><p>带有 <code>headers=&#123;&#39;X-Requested-With&#39;: &#39;XMLHttpRequest&#39;&#125;</code> 才能抓取到内容。</p><h3 id="HTTP-Cookie"><a href="#HTTP-Cookie" class="headerlink" title="HTTP Cookie"></a>HTTP Cookie</h3><p>虽然 <code>Cookie</code> 只是 HTTP Header 中的一个，但是因为非常重要，但是拿出来说一下。<code>Cookie</code> 被 HTTP 请求用来区分、追踪用户的身份，当你在一个网站登录的时候，就是通过写入 <code>Cookie</code> 字段来记录登录状态的。</p><p>当遇到需要登录的网站，你需要通过设置 Cookie 参数，来请求需要登录的内容。Cookie 可以通过开发者工具的请求面板，或者是资源面板中获得。在 pyspider 中，你也可以使用 <code>response.cookies</code> 获得返回的 cookie，并使用 <code>self.crawl(URL, cookie=&#123;&#39;key&#39;: &#39;value&#39;&#125;)</code> 来设置请求的 Cookie 参数。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;在上一篇教程中，我们使用 &lt;code&gt;self.crawl&lt;/code&gt; API 抓取豆瓣电影的 HTML 内容，并使用 CSS 选择器解析了一些内容。不过，现在的网站通过使用 &lt;a href=&quot;http://www.w3school.com.cn/ajax/ajax_in</summary>
      
    
    
    
    
    <category term="pyspider" scheme="https://binux.blog/tags/pyspider/"/>
    
    <category term="scrape" scheme="https://binux.blog/tags/scrape/"/>
    
    <category term="crawl" scheme="https://binux.blog/tags/crawl/"/>
    
    <category term="AJAX" scheme="https://binux.blog/tags/AJAX/"/>
    
    <category term="HTTP" scheme="https://binux.blog/tags/HTTP/"/>
    
  </entry>
  
  <entry>
    <title>pyspider 爬虫教程（一）：HTML 和 CSS 选择器</title>
    <link href="https://binux.blog/2015/01/pyspider-tutorial-level-1-html-and-css-selector/"/>
    <id>https://binux.blog/2015/01/pyspider-tutorial-level-1-html-and-css-selector/</id>
    <published>2015-01-04T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>虽然以前写过 <a href="http://blog.binux.me/2013/09/howto-crawl-web/">如何抓取WEB页面</a> 和 <a href="http://blog.binux.me/2014/07/how-to-extract-data-from-web/">如何从 WEB 页面中提取信息</a>。但是感觉还是需要一篇 step by step 的教程，不然没有一个总体的认识。不过，没想到这个教程居然会变成一篇<a href="http://docs.pyspider.org/en/latest/tutorial/HTML-and-CSS-Selector/">译文</a>，在这个爬虫教程系列文章中，会以实际的例子，由浅入深讨论爬取（抓取和解析）的一些关键问题。</p><p>在 教程一 中，我们将要爬取的网站是豆瓣电影：<a href="http://movie.douban.com/">http://movie.douban.com/</a></p><p>你可以在: <a href="http://demo.pyspider.org/debug/tutorial_douban_movie">http://demo.pyspider.org/debug/tutorial_douban_movie</a> 获得完整的代码，和进行测试。</p><h2 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h2><p>由于教程是基于 pyspider 的，你可以安装一个 pyspider（<a href="http://docs.pyspider.org/en/latest/Quickstart/">Quickstart</a>，也可以直接使用 pyspider 的 demo 环境： <a href="http://demo.pyspider.org/">http://demo.pyspider.org/</a>。</p><p>你还应该至少对万维网是什么有一个简单的认识：</p><ul><li><a href="http://zh.wikipedia.org/wiki/%E4%B8%87%E7%BB%B4%E7%BD%91">万维网</a>是一个由许多互相链接的超文本页面（以下简称网页）组成的系统。</li><li>网页使用网址（<a href="http://zh.wikipedia.org/wiki/%E7%BB%9F%E4%B8%80%E8%B5%84%E6%BA%90%E5%AE%9A%E4%BD%8D%E7%AC%A6">URL</a>）定位，并链接彼此</li><li>网页使用 <a href="http://zh.wikipedia.org/wiki/%E8%B6%85%E6%96%87%E6%9C%AC%E4%BC%A0%E8%BE%93%E5%8D%8F%E8%AE%AE">HTTP</a> 协议传输</li><li>网页使用 <a href="http://zh.wikipedia.org/wiki/HTML">HTML</a> 描述外观和语义</li></ul><p>所以，爬网页实际上就是：</p><ol><li>找到包含我们需要的信息的网址（URL）列表</li><li>通过 HTTP 协议把页面下载回来</li><li>从页面的 HTML 中解析出需要的信息</li><li>找到更多这个的 URL，回到 2 继续</li></ol><h2 id="选取一个开始网址"><a href="#选取一个开始网址" class="headerlink" title="选取一个开始网址"></a>选取一个开始网址</h2><p>既然我们要爬所有的电影，首先我们需要抓一个电影列表，一个好的列表应该：</p><ul><li>包含足够多的电影的 URL</li><li>通过翻页，可以遍历到所有的电影</li><li>一个按照更新时间排序的列表，可以更快抓到最新更新的电影</li></ul><p>我们在 <a href="http://movie.douban.com/">http://movie.douban.com/</a> 扫了一遍，发现并没有一个列表能包含所有电影，只能退而求其次，通过抓取分类下的所有的标签列表页，来遍历所有的电影： <a href="http://movie.douban.com/tag/">http://movie.douban.com/tag/</a> </p><h3 id="创建一个项目"><a href="#创建一个项目" class="headerlink" title="创建一个项目"></a>创建一个项目</h3><p>在 pyspider 的 dashboard 的右下角，点击 “Create” 按钮</p><p><img src="/assets/image/creating_project.png" alt="Creating a project"></p><p>替换 <code>on_start</code> 函数的 <code>self.crawl</code> 的 URL：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="meta">@every(<span class="params">minutes=<span class="number">24</span> * <span class="number">60</span></span>)</span></span><br><span class="line"><span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">    self.crawl(<span class="string">&#x27;http://movie.douban.com/tag/&#x27;</span>, callback=self.index_page)</span><br></pre></td></tr></table></figure><blockquote><ul><li><code>self.crawl</code> 告诉 pyspider 抓取指定页面，然后使用 <code>callback</code> 函数对结果进行解析。</li><li><a href="(http://docs.pyspider.org/en/latest/apis/@every/)"><code>@every</code></a> 修饰器，表示 <code>on_start</code> 每天会执行一次，这样就能抓到最新的电影了。</li></ul></blockquote><p>点击绿色的 <code>run</code> 执行，你会看到 <code>follows</code> 上面有一个红色的 1，切换到 <code>follows</code> 面板，点击绿色的播放按钮：</p><p><img src="/assets/image/run_one_step.png" alt="Run ont step"></p><h2 id="Tag-列表页"><a href="#Tag-列表页" class="headerlink" title="Tag 列表页"></a>Tag 列表页</h2><p>在 <a href="http://movie.douban.com/tag/">tag 列表页</a> 中，我们需要提取出所有的 电影列表页 的 URL。你可能已经发现了，sample handler 已经提取了非常多大的 URL，所有，一种可行的提取列表页 URL 的方法就是用正则从中过滤出来：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> re</span><br><span class="line">...</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(<span class="params">age=<span class="number">10</span> * <span class="number">24</span> * <span class="number">60</span> * <span class="number">60</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">index_page</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">&#x27;a[href^=&quot;http&quot;]&#x27;</span>).items():</span><br><span class="line">            <span class="keyword">if</span> re.<span class="keyword">match</span>(<span class="string">&quot;http://movie.douban.com/tag/\w+&quot;</span>, each.attr.href, re.U):</span><br><span class="line">                self.crawl(each.attr.href, callback=self.list_page)</span><br></pre></td></tr></table></figure><blockquote><ul><li>由于 电影列表页和 tag列表页长的并不一样，在这里新建了一个 <code>callback</code> 为 <code>self.list_page</code></li><li><code>@config(age=10 * 24 * 60 * 60)</code> 在这表示我们认为 10 天内页面有效，不会再次进行更新抓取</li></ul></blockquote><p>由于 pyspider 是纯 Python 环境，你可以使用 Python 强大的内置库，或者你熟悉的第三方库对页面进行解析。不过更推荐使用 CSS选择器。</p><h2 id="电影列表页"><a href="#电影列表页" class="headerlink" title="电影列表页"></a>电影列表页</h2><p>再次点击 <code>run</code> 让我们进入一个电影列表页(<code>list_page</code>)。在这个页面中我们需要提取：</p><ul><li>电影的链接，例如，<a href="http://movie.douban.com/subject/1292052/">http://movie.douban.com/subject/1292052/</a></li><li>下一页的链接，用来翻页</li></ul><h3 id="CSS选择器"><a href="#CSS选择器" class="headerlink" title="CSS选择器"></a>CSS选择器</h3><p>CSS选择器，顾名思义，是 <a href="http://www.w3school.com.cn/css/css_intro.asp">CSS</a> 用来定位需要设置样式的元素 所使用的表达式。既然前端程序员都使用 CSS选择器 为页面上的不同元素设置样式，我们也可以通过它定位需要的元素。你可以在 <a href="http://www.w3school.com.cn/cssref/css_selectors.asp">CSS 选择器参考手册</a> 这里学习更多的 CSS选择器 语法。</p><p>在 pyspider 中，内置了 <code>response.doc</code> 的 <a href="https://pythonhosted.org/pyquery/">PyQuery</a> 对象，让你可以使用类似 jQuery 的语法操作 DOM 元素。你可以在 <a href="https://pythonhosted.org/pyquery/">PyQuery</a> 的页面上找到完整的文档。</p><h3 id="CSS-Selector-Helper"><a href="#CSS-Selector-Helper" class="headerlink" title="CSS Selector Helper"></a>CSS Selector Helper</h3><p>在 pyspider 中，还内置了一个 <code>CSS Selector Helper</code>，当你点击页面上的元素的时候，可以帮你生成它的 CSS选择器 表达式。你可以点击 <code>Enable CSS selector helper</code> 按钮，然后切换到 <code>web</code> 页面：</p><p><img src="/assets/image/css_selector_helper.png" alt="css selector helper"></p><p>开启后，鼠标放在元素上，会被黄色高亮，点击后，所有拥有相同 CSS选择器 表达式的元素会被高亮。表达式会被插入到 python 代码当前光标位置。创建下面的代码，将光标停留在单引号中间：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">list_page</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">&#x27;&#x27;</span>).items():</span><br></pre></td></tr></table></figure><p>点击一个电影的链接，CSS选择器 表达式将会插入到你的代码中，如此重复，插入翻页的链接：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">list_page</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">&#x27;HTML&gt;BODY&gt;DIV#wrapper&gt;DIV#content&gt;DIV.grid-16-8.clearfix&gt;DIV.article&gt;DIV&gt;TABLE TR.item&gt;TD&gt;DIV.pl2&gt;A&#x27;</span>).items():</span><br><span class="line">        self.crawl(each.attr.href, callback=self.detail_page)</span><br><span class="line">    <span class="comment"># 翻页</span></span><br><span class="line">    <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">&#x27;HTML&gt;BODY&gt;DIV#wrapper&gt;DIV#content&gt;DIV.grid-16-8.clearfix&gt;DIV.article&gt;DIV.paginator&gt;A&#x27;</span>).items():</span><br><span class="line">        self.crawl(each.attr.href, callback=self.list_page)</span><br></pre></td></tr></table></figure><blockquote><ul><li>翻页是一个到自己的 <code>callback</code> 回调</li></ul></blockquote><h2 id="电影详情页"><a href="#电影详情页" class="headerlink" title="电影详情页"></a>电影详情页</h2><p>再次点击 <code>run</code>，follow 到详情页。使用 <code>css selector helper</code> 分别添加电影标题，打分和导演：</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">def</span> <span class="title function_">detail_page</span>(<span class="params">self, response</span>):</span><br><span class="line">    <span class="keyword">return</span> &#123;</span><br><span class="line">        <span class="string">&quot;url&quot;</span>: response.url,</span><br><span class="line">        <span class="string">&quot;title&quot;</span>: response.doc(<span class="string">&#x27;HTML&gt;BODY&gt;DIV#wrapper&gt;DIV#content&gt;H1&gt;SPAN&#x27;</span>).text(),</span><br><span class="line">        <span class="string">&quot;rating&quot;</span>: response.doc(<span class="string">&#x27;HTML&gt;BODY&gt;DIV#wrapper&gt;DIV#content&gt;DIV.grid-16-8.clearfix&gt;DIV.article&gt;DIV.indent.clearfix&gt;DIV.subjectwrap.clearfix&gt;DIV#interest_sectl&gt;DIV.rating_wrap.clearbox&gt;P.rating_self.clearfix&gt;STRONG.ll.rating_num&#x27;</span>).text(),</span><br><span class="line">        <span class="string">&quot;导演&quot;</span>: [x.text() <span class="keyword">for</span> x <span class="keyword">in</span> response.doc(<span class="string">&#x27;a[rel=&quot;v:directedBy&quot;]&#x27;</span>).items()],</span><br><span class="line">    &#125;</span><br></pre></td></tr></table></figure><p>注意，你会发现 <code>css selector helper</code> 并不是总是能提取到合适的 CSS选择器 表达式。你可以在 <a href="https://developer.chrome.com/devtools">Chrome Dev Tools</a> 的帮助下，写一个合适的表达式：</p><p><img src="/assets/image/chrome_dev_tools.png" alt="Chrome Dev Tools"></p><p>右键点击需要提取的元素，点击审查元素。你并不需要像自动生成的表达式那样写出所有的祖先节点，只要写出那些能区分你不需要的元素的关键节点的属性就可以了。不过这需要抓取和网页前端的经验。所以，学习抓取的最好方法就是学会这个页面&#x2F;网站是怎么写的。</p><p>你也可以在 Chrome Dev Tools 的 Javascript Console 中，使用 <code>$$(a[rel=&quot;v:directedBy&quot;])</code> 测试 CSS Selector。</p><h2 id="开始抓取"><a href="#开始抓取" class="headerlink" title="开始抓取"></a>开始抓取</h2><ol><li>使用 <code>run</code> 单步调试你的代码，对于用一个 <code>callback</code> 最好使用多个页面类型进行测试。<strong>然后保存。</strong></li><li>回到 Dashboard，找到你的项目</li><li>将 <code>status</code> 修改为 <code>DEBUG</code> 或 <code>RUNNING</code></li><li>按 <code>run</code> 按钮</li></ol><p><img src="/assets/image/pyspider_index_page.png" alt="pyspider index page"></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;虽然以前写过 &lt;a href=&quot;http://blog.binux.me/2013/09/howto-crawl-web/&quot;&gt;如何抓取WEB页面&lt;/a&gt; 和 &lt;a href=&quot;http://blog.binux.me/2014/07/how-to-extract-data-</summary>
      
    
    
    
    
    <category term="css selector" scheme="https://binux.blog/tags/css-selector/"/>
    
    <category term="pyspider" scheme="https://binux.blog/tags/pyspider/"/>
    
    <category term="scrape" scheme="https://binux.blog/tags/scrape/"/>
    
    <category term="crawl" scheme="https://binux.blog/tags/crawl/"/>
    
  </entry>
  
  <entry>
    <title>迁移 Python 3</title>
    <link href="https://binux.blog/2014/12/porting-to-python-3/"/>
    <id>https://binux.blog/2014/12/porting-to-python-3/</id>
    <published>2014-12-21T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>使用 Python 3 的呼声一直很高，Python 3 解决了很多 2 中的坑，比如 unicode，在向他们解释为什么 <code>print str</code> 乱码，<code>fp.write(str)</code> 时报错，在什么时候需要 <code>encode</code>，更容易了。</p><p>但是由于一开始接触的就是 Python 2，熟悉的包都是 Python 2（我也不确定他们是否支持 Python 3）。公司机器上的 Python 2.7 就算是“最新”版本。于是一直没有升级。不过有一种说法，切换到 Python 3 的最好时机就是现在。-为了庆祝 star 过 3000-，由于见到两次要求支持 Python 3，用一个周末为 pyspider 加入了 Python 3 支持（怎么样，不难吧）。</p><p>主要参考：</p><ul><li><a href="https://docs.python.org/3/howto/pyporting.html">Porting Python 2 Code to Python 3</a></li><li><a href="http://python-future.org/compatible_idioms.html">Cheat Sheet: Writing Python 2-3 compatible code</a></li><li><a href="https://pythonhosted.org/six/">Six: Python 2 and 3 Compatibility Library</a></li></ul><h2 id="开始之前"><a href="#开始之前" class="headerlink" title="开始之前"></a>开始之前</h2><p>其实 <a href="https://docs.python.org/3/howto/pyporting.html">Porting Python 2 Code to Python 3</a> 这篇文章是一个非常好的索引，能让你对将要进行的工作有一个整体的把握，同时能提供细节的链接，能让你立即开始工作。而且这一节内容就来自此文的 <a href="https://docs.python.org/3/howto/pyporting.html#the-short-explanation">The Short Explanation</a> 一节。因为总结得很好，所以就不重复造轮子了。</p><p>首先，低版本的 Python 2 与 Python 3 之间的鸿沟太大了，特别是 Python 2.5(含) 以前的版本。要同时兼容他们的代价太大。而 Python 2.6 和 Python 2.7 已经带有部分 Python 3 的特性，这让迁移的代价大大降低了。同时，不建议支持 Python 3.3 以下的 3 字头版本，由于 Python 3 实际上已经 release 6 年了，这些 Python 3.x 版本也比较老了，很多特性还没有，或者包不支持。所以建议跳过他们。</p><p>其次，一定要有测试，保证测试足够的代码覆盖。Python 2 到 Python 3 从包改名到语法都有变化，几乎所有的代码都需要有修改。足够的代码覆盖，才能在这样大规模修改中，保证所有功能可用。而 pyspider 正是因为有 86% 的代码覆盖，我能这么快地完成代码迁移。</p><p>读一读 Python 2 和 Python 3 有什么不同。这个可以看看 <a href="https://docs.python.org/3/whatsnew/index.html">What’s New in Python</a>，特别是 <a href="https://docs.python.org/3/whatsnew/3.0.html">What’s New In Python 3.0</a>。当然也可以找一些中文的文章，这个方面应该还蛮多的。反正最主要的就是大量的包改名，以及 <code>bytes</code>, <code>str</code>, <code>unicode</code> 三者的变化。或者你可以先读一读 <a href="http://python-future.org/compatible_idioms.html">Cheat Sheet</a>，虽然等下我们还需要它。</p><p>好，现在可以来看看你的包依赖是否支持 Python 3 了。并不是 pip 能安装的包就是支持 Python 3 的，可能装上了依旧不能工作。你可以用 <a href="https://caniusepython3.com/">Can I Use Python 3</a> 检测包是否支持。不过我更推荐 <a href="https://python3wos.appspot.com/">PYTHON 3 WALL OF SUPERPOWERS</a> （需要翻墙）。不过也不用担心，大部分包都是支持 Python 3 的，如果不支持，一般都会有替代，例如 pika 就可以被 ampq 替换，而 MySQL-python 能被 mysql-connector-python 替代。</p><h2 id="第一步——查找替换"><a href="#第一步——查找替换" class="headerlink" title="第一步——查找替换"></a>第一步——查找替换</h2><p>首先我们从大的方向入手，把一些改名了的包和函数处理一下。请打开 <a href="http://python-future.org/compatible_idioms.html">Cheat Sheet: Writing Python 2-3 compatible code</a> 参照它们一条条进行。在能搜索的地方，使用搜索统一修改，不然挨个文件太慢，而且会忘记的。因为我用的是 six 作为多环境间的桥梁。所以需要同时参考 <a href="https://pythonhosted.org/six/">six的文档</a>。你可能需要打开两个窗口，同时运行 Python 2 和 Python 3，确认语句在两个环境下都能执行。</p><p>在这一步，我做了以下处理：</p><ul><li>相对导入 - <a href="http://python-future.org/compatible_idioms.html#imports-relative-to-a-package">Imports relative to a package</a></li><li>urlparse &#x2F; urllib 库改名 - <a href="https://pythonhosted.org/six/#module-six.moves.urllib.parse">six</a></li><li>thread 包改名，而且 <code>get_ident</code> 函数不再存在了。将 <code>thread.get_ident()</code> 改为 <code>threading.current_thread().ident</code> <a href="https://pythonhosted.org/six/#module-six.moves">six</a></li><li><code>basestring</code> 类型不再存在，用 <code>six.string_types</code> 代替 <a href="http://python-future.org/compatible_idioms.html#basestring">sheet</a></li><li><code>__metaclass__</code> 不再存在，用 <code>six.add_metaclass</code> 代替 <a href="http://python-future.org/compatible_idioms.html#metaclasses">sheet</a></li><li><code>UserDict.DictMixin</code> 不再存在，用 <code>collections.Mapping</code> 或者 <code>collections.MutableMapping</code> 代替</li><li><code>/</code> 现在是真的除法了，也就是说 int &#x2F; int 会得到一个 float，使用 <code>//</code> 获得地板除效果（由于在 python 中，地板除用得少，实际上不改关系不大） <a href="http://python-future.org/compatible_idioms.html#division">sheet</a></li><li><code>StringIO</code> 现在分为 <code>io.BytesIO</code> 和 <code>io.StringIO</code> 视情况使用</li><li>print 现在是一个 function 了 <a href="http://python-future.org/compatible_idioms.html#stringio">sheet</a></li><li><code>unicode</code> 关键字不再存在 使用 <code>six.text_type</code> 代替</li><li><code>__builtins__</code> 不存在了，<a href="https://pythonhosted.org/six/#module-six.moves"><code>six.moves.builtins</code></a> <a href="http://python-future.org/compatible_idioms.html#unicode-text-string-literals">sheet</a></li><li><code>reload</code> 改为 <a href="https://pythonhosted.org/six/#module-six.moves"><code>six.reload_module</code></a></li><li>dict 的 <code>keys</code>， <code>items</code>， <code>values</code> 现在都是迭代器了，不返回列表，原来的 <code>iteritems</code>, <code>itervalues</code> 不再存在，使用 <a href="https://pythonhosted.org/six/#six.iterkeys">six.iterkeys</a> 等函数代替。</li><li><code>raise exc_type, exc_value, tb</code> 的形式不再支持，使用 <code>six.reraise(exc_type, exc_value, tb)</code> 代替。</li></ul><p>其他的例如 try…catch，如果你在 Python 2 中就比较标准地使用 <code>as</code>，那么这时就不用修改了。</p><p>另外，如果你和我一样有 str(object) 来获得 object 的文字结果的习惯话，每次写 <code>six.text_type(object)</code> 太长了。可以写一些兼容性函数，然后在整个项目中使用。</p><p>注意到这里，我们并没有处理 <code>bytes</code>, <code>string</code>, <code>unicode</code>，请放下他们，我们在下一节处理这些问题。</p><h2 id="第二步——处理-unicode"><a href="#第二步——处理-unicode" class="headerlink" title="第二步——处理 unicode"></a>第二步——处理 unicode</h2><p>由于在 Python 3 中，所有的 <code>&#39;text&#39;</code> 都变成 unicode 了，所以你会觉得它会是一个大问题，是否需要给所有的 <code>&#39;text&#39;</code> 加上 <code>u</code> ，或者干脆所有文件都加上 <code>from __future__ import unicode_literals</code>？</p><p>实际上，大部分时候不需要。</p><p>在 Python 2 中，我们很少有意识地区分 <code>str</code> 和 <code>unicode</code>，对于大部分函数调用来说，给它 <code>str</code> 或者 <code>unicode</code> 都是一样的，因为他们共享大部分行为。但是在 Python 3 中，<code>bytes</code> 和 <code>str</code>(<code>unicode</code>) 却大不一样。例如当你 <code>for c in bytes</code> 时，得到的是一个 <code>int</code> 而不是一个 <code>str</code>。</p><p>虽然不做任何修改，<code>&#39;text&#39;</code> 在 Python 2 中，是 <code>str</code>(<code>bytes</code>)，而在 Python 3 中是 <code>str</code>(<code>unicode</code>)。但是提交给函数时，既然 Python 2 的函数同时支持 <code>str</code> 和 <code>unicode</code>，所以没有任何问题。而且，在 Python 2 中，<code>&#39;text&#39;+u&#39;中文&#39;</code> 会自动升级为 <code>unicode</code>，所以，只需要注意在出现中文的地方使用 <code>u&#39;中文&#39;</code> 就好了（即使在 Python 2 中，这也是一个好的习惯）。而 <code>b&#39;bytes&#39;</code> 的场合非常少，更多的是使用 <code>text.encode</code> 进行转换。所以，对于习惯良好的 Python 2 代码来说，是几乎不需要修改的。</p><p>除了源代码之中的 unicode 问题，其他主要问题出现在输入输出上。但是，只要遵循：程序中流通的数据，只能是 unicode。数据进来之后必须转换成 unicode 即可。</p><h2 id="最后"><a href="#最后" class="headerlink" title="最后"></a>最后</h2><p>运行测试，哪报错改哪就好了。</p>]]></content>
    
    
    <summary type="html">porting pyspider project to Python 3 with Python 2 compatible</summary>
    
    
    
    
    <category term="python" scheme="https://binux.blog/tags/python/"/>
    
    <category term="porting" scheme="https://binux.blog/tags/porting/"/>
    
  </entry>
  
  <entry>
    <title>pyspider介绍</title>
    <link href="https://binux.blog/2014/11/introduction-to-pyspider/"/>
    <id>https://binux.blog/2014/11/introduction-to-pyspider/</id>
    <published>2014-11-16T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>虽然已经发过一篇<a href="http://blog.binux.me/2014/02/pyspider-architecture/">架构设计</a>，但是觉得还是有必要发一篇介绍。而且拖了那么久的第二里程碑的commit数已经超过第一个版本了。。</p><p>那么由我再次介绍一下 pyspider。</p><h1 id="缘起"><a href="#缘起" class="headerlink" title="缘起"></a>缘起</h1><p>pyspider 来源于以前做的一个垂直搜索引擎使用的爬虫后端。我们需要从200个站点（由于站点失效，不是都同时啦，同时有100+在跑吧）采集数据，并要求在5分钟内将对方网站的更新更新到库中。</p><p>所以，灵活的抓取控制是必须的。同时，由于100个站点，每天都可能会有站点失效或者改版，所以需要能够监控模板失效，以及查看抓取状态。</p><p>为了达到5分钟更新，我们使用抓取最近更新页上面的最后更新时间，以此来判断页面是否需要再次抓取。</p><p>可见，这个项目对于爬虫的监控和调度要求是非常高的。</p><h1 id="pyspider-的主要特性"><a href="#pyspider-的主要特性" class="headerlink" title="pyspider 的主要特性"></a>pyspider 的主要特性</h1><ul><li>python 脚本控制，可以用任何你喜欢的html解析包（内置 pyquery）</li><li>WEB 界面编写调试脚本，起停脚本，监控执行状态，查看活动历史，获取结果产出</li><li>支持 MySQL, MongoDB, SQLite</li><li>支持抓取 JavaScript 的页面</li><li>组件可替换，支持单机&#x2F;分布式部署，支持 Docker 部署</li><li>强大的调度控制</li></ul><p>由于功能太多，更多请参考<a href="https://github.com/binux/pyspider/wiki/%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97">脚本编写指南</a></p><p>感谢 <a href="https://plus.google.com/u/0/+PhoenixNemo/">+PhoenixNemo</a> 提供的VPS，提供了一个 demo： <a href="http://demo.pyspider.org/">demo.pyspider.org</a>。无需安装即可体验。</p><p><a href="http://demo.pyspider.org/"><img src="http://ww1.sinaimg.cn/large/7d46d69fjw1emavy6e9gij21kw0uldvy.jpg" alt="demo"></a></p><h1 id="脚本样例"><a href="#脚本样例" class="headerlink" title="脚本样例"></a>脚本样例</h1><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> libs.base_handler <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="keyword">class</span> <span class="title class_">Handler</span>(<span class="title class_ inherited__">BaseHandler</span>):</span><br><span class="line">    <span class="string">&#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="string">    this is a sample handler</span></span><br><span class="line"><span class="string">    &#x27;&#x27;&#x27;</span></span><br><span class="line"><span class="meta">    @every(<span class="params">minutes=<span class="number">24</span>*<span class="number">60</span>, seconds=<span class="number">0</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">on_start</span>(<span class="params">self</span>):</span><br><span class="line">        self.crawl(<span class="string">&#x27;http://scrapy.org/&#x27;</span>, callback=self.index_page)</span><br><span class="line"></span><br><span class="line"><span class="meta">    @config(<span class="params">age=<span class="number">10</span>*<span class="number">24</span>*<span class="number">60</span>*<span class="number">60</span></span>)</span></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">index_page</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">for</span> each <span class="keyword">in</span> response.doc(<span class="string">&#x27;a[href^=&quot;http://&quot;]&#x27;</span>).items():</span><br><span class="line">            self.crawl(each.attr.href, callback=self.detail_page)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">def</span> <span class="title function_">detail_page</span>(<span class="params">self, response</span>):</span><br><span class="line">        <span class="keyword">return</span> &#123;</span><br><span class="line">                <span class="string">&quot;url&quot;</span>: response.url,</span><br><span class="line">                <span class="string">&quot;title&quot;</span>: response.doc(<span class="string">&#x27;title&#x27;</span>).text(),</span><br><span class="line">                &#125;</span><br></pre></td></tr></table></figure><p>例如这就是创建任务后默认生成的一个脚本示例。</p><ul><li>通过 <code>on_start</code> 回调函数，作为爬取的入口点，当点击主面板上的 <code>run</code> 的时候，就是调用这个函数，启动抓取。</li><li><code>self.crawl</code> 告诉调度器，我们需要抓取 <code>&#39;http://scrapy.org/&#39;</code> 这个页面，然后使用 <code>callback=self.index_page</code> 这个回调函数进行解析。</li><li>所有 <code>return</code> 的内容默认会被捕获到 <code>resultdb</code> 中，可以直接在 WEBUI 上看到。</li></ul><h1 id="更多特性和文档"><a href="#更多特性和文档" class="headerlink" title="更多特性和文档"></a>更多特性和文档</h1><ul><li><a href="https://github.com/binux/pyspider/wiki">Wiki</a></li><li><a href="https://github.com/binux/pyspider/wiki/%E5%BF%AB%E9%80%9F%E6%8C%87%E5%8D%97">快速指南</a></li><li><a href="https://github.com/binux/pyspider/wiki/%E8%84%9A%E6%9C%AC%E7%BC%96%E5%86%99%E6%8C%87%E5%8D%97">脚本编写指南</a></li></ul>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;虽然已经发过一篇&lt;a href=&quot;http://blog.binux.me/2014/02/pyspider-architecture/&quot;&gt;架构设计&lt;/a&gt;，但是觉得还是有必要发一篇介绍。而且拖了那么久的第二里程碑的commit数已经超过第一个版本了。。&lt;/p&gt;
&lt;p&gt;那么</summary>
      
    
    
    
    
    <category term="python" scheme="https://binux.blog/tags/python/"/>
    
    <category term="javascript" scheme="https://binux.blog/tags/javascript/"/>
    
    <category term="crawler" scheme="https://binux.blog/tags/crawler/"/>
    
    <category term="opensource" scheme="https://binux.blog/tags/opensource/"/>
    
  </entry>
  
  <entry>
    <title>签到 —— qiandao.today 介绍</title>
    <link href="https://binux.blog/2014/09/introduction-to-qiandao-today/"/>
    <id>https://binux.blog/2014/09/introduction-to-qiandao-today/</id>
    <published>2014-09-29T07:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p><a href="https://qiandao.today/">qiandao.today</a> 已经上线了一个半月，这篇blog一个半月以前就应该写了。直到我刷了14遍水晶塔没有ROLL到任何装备（不对，我最后通过贪婪ROLL到了！），打了两晚麻将，把把最小胡牌距离大于5（任意更换手牌达到胡牌的最小张数），房子里刷JJ怪之后。我觉得我必须做点什么。。。</p><p>好了，不扯蛋了。自动签到是我对于 “如何请求到数据” ，进行请求自动分析的一个尝试（实际是我 <a href="http://u2.dmhy.org/">U2</a> 因为45天没登录被封了）。通过<strong>浏览器捕获页面请求瀑布流，进行内容&#x2F;请求分析，找出关键请求</strong>。所以，签到这个项目，我就是先从 <a href="https://qiandao.today/har/edit">HAR编辑器</a> 开始做的。做的时候还玩了一下 <a href="http://angularjs.org/">angularjs</a>。<del>然后其他部分都是随便写的</del></p><p>但是，对于签到来说，哪些请求是必要的，这个请求是怎么组装的（例如 token 参数怎么来），特征不明显。自动分析出来就能直接用的概率太低了，即使是人还得单步测试呢。于是 HAR编辑器 成为编辑和单步调试的辅助。自动分析变成了 “推荐相关请求”。</p><ul><li>用户部分系统尝试了一下 <a href="http://en.wikipedia.org/wiki/PBKDF2">PBKDF2</a> 进行密码加密。PBKDF2 的优势在于通过随机盐 加 可配置的多轮加密，加大了单个key的运算代价。</li><li>模板执行部分通过提取页面信息，和 jinja2 引擎渲染，可以动态地改变请求的 url、header、data 各个部分。</li><li>执行断言加上邮件系统，可以检测签到是否成功，在失败的时候给用户发送邮件提醒。</li></ul><p>本来还想要做互助打码的验证码系统的，但是通过 <a href="https://plus.google.com/u/0/+%E9%9B%AA%E6%9C%88%E7%A7%8B%E6%B0%B4%E9%85%B1">雪月秋水</a> 的 <a href="https://github.com/acgotaku/GetCookies">cookie插件</a>，其实大部分只有登录需要验证码，签到并不需要。<del>关键是做这个东西不好玩</del>，于是就算了。</p><p>运行了一个半月，目前有11个公开签到模板，400+个签到任务，每天进行300次签到。不过由于担心单IP登录帐号过多被封，只在v2ex做了一次广告，不敢大范围推广。。。</p><hr><p>以下是面向普通用户的简介：</p><ul><li>云代签</li><li>支持多个网站</li><li>失败邮件提醒</li><li>自制模板并分享（<a href="https://github.com/binux/qiandao/blob/master/docs/har-howto.md">文档</a>）</li><li>https 传输安全保证</li><li>一号一密用户数据加密</li><li>开放源码，支持本地执行（提供本地lite版）</li></ul><p>github: <a href="https://github.com/binux/qiandao">binux&#x2F;qiandao</a><br>网站: <a href="https://qiandao.today/">https://qiandao.today</a></p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;&lt;a href=&quot;https://qiandao.today/&quot;&gt;qiandao.today&lt;/a&gt; 已经上线了一个半月，这篇blog一个半月以前就应该写了。直到我刷了14遍水晶塔没有ROLL到任何装备（不对，我最后通过贪婪ROLL到了！），打了两晚麻将，把把最小胡牌距离大</summary>
      
    
    
    
    
    <category term="qiandao.today" scheme="https://binux.blog/tags/qiandao-today/"/>
    
  </entry>
  
  <entry>
    <title>如何从 WEB 页面中提取信息</title>
    <link href="https://binux.blog/2014/07/how-to-extract-data-from-web/"/>
    <id>https://binux.blog/2014/07/how-to-extract-data-from-web/</id>
    <published>2014-07-19T07:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>已经五个月没有更新 blog 了，这五个月全身心投入到了两个关于如何从页面上抽取结构化数据的项目上。这也是我加入某厂最主要的原因。其中一个全自动模板生成抽取器，虽然还不完全能够实用，但比1年前效果好太多，同时也让我想明白了一些问题。这都是下文主要讨论的问题。</p><p>关于 <a href="https://github.com/binux/pyspider">pyspider</a> 项目，这几天我也在慢慢填上这延期了3个月的坑，至少完成第二里程碑吧。但缺少实际应用的环境，很多东西是否工作得很好，我也不是很有把握。如果有的话，还是希望支持1-2个实际的抓取项目吧。</p><p>而 “如何获得页面&#x2F;数据” 这个问题依旧是我持续关注中，想要去解决的问题。但是，既然某厂的后续解决方案是将所有抓取页面过 webkit 渲染（虽然很多时候渲染不出 或 需要点击动作，代价往往大于直接抓 API），不会有很多精力投入，待我慢慢想想。。</p><p>##四种解析模式</p><h3 id="xpath-x2F-css选择器-x2F-正则表达式"><a href="#xpath-x2F-css选择器-x2F-正则表达式" class="headerlink" title="xpath &#x2F; css选择器 &#x2F; 正则表达式"></a>xpath &#x2F; css选择器 &#x2F; 正则表达式</h3><p><strong>示例:</strong> <a href="https://www.kimonolabs.com/">https://www.kimonolabs.com/</a></p><p>通过手动、自动、半自动方式，设定需要抽取元素的 <a href="http://www.w3schools.com/xpath/default.asp">xpath</a>、 <a href="http://www.w3schools.com/cssref/css_selectors.asp">css选择器</a> 或 正则表达式 进行定位提取的方法（这里需要指出的是，html 并不是正则的，正则表达式可能在部分简单提取时有效，但 <strong>不要用正则表达式进行页面提取</strong>）。其根本思想是提供一种定位元素的规则进行页面抽取。</p><p>这个方法被用得最多，好处是有效，嗯。缺陷在于用户需要会 xpath &#x2F; css选择器 &#x2F; 正则语法，虽然有一些工具（例如上面的kimono、chrome的调试工具、pyspider里面的脚本）辅助生成规则，但可能通用性不足 或 区分度不够，选取到不需要的内容。这在大批量抽取时需要大量的高级人力去配置，即使是熟练工也需要5-10分钟配置一个页面（6-8个属性），需要耗费大量精力。</p><p>这种抽取方式的一种变形是：将 key 和 value 同时在页面中标出，通过 key 和 value 总是穿插出现的这一假设，省去单独为每个属性设置规则的人力，极大增快标注效率。<br>例如：<a href="http://movie.douban.com/subject/7054604/">http://movie.douban.com/subject/7054604/</a> 这个页面中的  </p><blockquote><p>导演: 迈克尔·贝<br>编剧: 伊伦·克鲁格<br>主演: 马克·沃尔伯格…<br>类型: 动作 &#x2F; 科幻 &#x2F; 冒险<br>制片国家&#x2F;地区: 美国 &#x2F; 中国大陆<br>语言: 英语 &#x2F; 汉语普通话 &#x2F; 粤语<br>上映日期: 2014-06-27(美国&#x2F;中国大陆)<br>片长: 166分钟<br>又名: 变形金刚：歼灭世纪(港) &#x2F; 变形金刚4：灭绝时代 &#x2F; 变形金刚4 &#x2F; 变4 &#x2F; Transformers 4<br>IMDb链接: tt2109248  </p></blockquote><p>导演&#x2F;编剧&#x2F;类型等 属性名 往往拥有相同的 xpath，而值的 xpath 也是独立的几种。他们一定是 key: value 的形式组织的，通过用 key 分割 value 的方式能轻松将所有信息提取出来。</p><h3 id="data-highlighter"><a href="#data-highlighter" class="headerlink" title="data highlighter"></a>data highlighter</h3><p><strong>示例:</strong> <a href="http://googlewebmastercentral.blogspot.com/2012/12/introducing-data-highlighter-for-event.html">http://googlewebmastercentral.blogspot.com/2012/12/introducing-data-highlighter-for-event.html</a></p><p>Data Highlighter 的标注方式是：给一系列相似的页面，让用户标出（高亮）每个属性在页面中的位置。通过多个页面的标注信息，寻找每个属性的特征。当然了，这个特征可以是 xpath，也可以是上下文，也有可能是机器学习的特征向量。</p><p>Data Hightlighter 通过高亮 <strong>多个页面中相同属性</strong> 进行规则学习，省去了人为设置规则时的学习成本。实践表明，在单一页面模板下，标记2个页面就足以生成规则了。效率远大于手工设置规则。Google Data Highlighter 甚至对文字进行了切分，能在 <code>英语 / 汉语普通话 / 粤语</code> xpath 相同的情况下，分别选出三种语言。是我目前见过的成熟度最高、通用性最好、最简便的数据抽取方式。</p><h3 id="micro-data"><a href="#micro-data" class="headerlink" title="micro-data"></a>micro-data</h3><p><strong>示例:</strong> <a href="http://microformats.org/">http://microformats.org/</a> 以及各大网站</p><p>页面属性标记，通过在页面数据元素上增加属性标识，通过开放的标准格式，为数据提取提供便利，例如这是豆瓣的评论数据：</p><figure class="highlight plaintext"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">&lt; p class=&quot;rating_self clearfix&quot; typeof=&quot;v:Rating&quot;&gt;</span><br><span class="line">  &lt;span class=&quot;ll bigstar35&quot;&gt;&lt;/span&gt;</span><br><span class="line">  &lt;strong class=&quot;ll rating_num&quot; property=&quot;v:average&quot;&gt;6.7&lt;/strong&gt;</span><br><span class="line">  &lt;span property=&quot;v:best&quot; content=&quot;10.0&quot;&gt;&lt;/span&gt;</span><br><span class="line">&lt;/p&gt;</span><br></pre></td></tr></table></figure><p><code>typeof=&quot;v:Rating&quot;</code> 表明这里是 rating 数据，<code>v:best</code> 表明 rating 的最大值。通过开放的 data format 标准，只按照标准抽取，就能得到包含的结构化数据。但是，需要站长的支持，在页面中加入标记才可以。</p><p>从广义上讲，主图识别，页面发布时间这样的属性，其实也可以是通过对页面内容进行分析获得的。这与 micro-data 一样，通过元素足够强的特征，对元素的含义进行理解分析。</p><h3 id="模板生成与提取"><a href="#模板生成与提取" class="headerlink" title="模板生成与提取"></a>模板生成与提取</h3><p><img src="/assets/image/screenshot_2014-06-17_19.49.40.png" alt="image"></p><p>页面模板（wrapper）抽取是基于这样一个假设：结构化页面都是 通过模板 将数据库中的数据 映射成页面的。通过页面分析，得到页面模板，通过模板提取出实际的结构化数据。</p><p>例如，我使用过的方法，将多个相似页面放在一起比对，寻找等位节点（具有相同结构或表示相同数据类型的元素），将 DOM树 合并。通过比较不同页面上的同类节点，能够获知页面中哪部分是变化的，哪部分是不变的。变化的部分为数据，不变部分为模板。最后形成如上图所示的模板，页面变化部分被涂黑。这个方法类似于将多张纸叠在一起，透过光去看，就会发现变化的文字部分会比其他部分更黑。</p><p>当然了，这个方法也有缺陷，例如：<a href="http://www.xdowns.com/soft/1/2/2006/Soft_34115.html">页面一</a>，<a href="http://www.xdowns.com/soft/10/35/2007/Soft_34731.html">页面二</a> 的标题部分，一个是蓝色，一个是绿色，虽然在人类视觉上它们相差不大，但从页面结构上绿色多了一层 <code>&lt;font&gt;</code>，作为算法很难理解，这样的样式表示他们是否有相同的含义，是否有区别。同理左侧推荐的蓝绿相间，即使作为人也很难理解它们有什么区别。</p><p>##两个核心问题</p><p>总结起来，以上四种解析模式都在尝试解决以下两个问题：</p><h3 id="一个元素在说什么"><a href="#一个元素在说什么" class="headerlink" title="一个元素在说什么"></a>一个元素在说什么</h3><p>当你打开一个页面，你怎么知道一个页面在传递什么信息？你怎么知道一个元素是文章的标题？怎么知道一个元素是作者？作为人类，我们可能会看到一个元素的位置是否在页面中间，元素的字体大小、颜色，元素前面是不是有一个 “作者：”，元素内容是否长得像一个人名&#x2F;时间，上下文中这个元素都在讲什么，这篇文章是什么领域，等等。人类可能会有非常多的 <strong>经验知识</strong> ，当看到一个页面的时候能够解读出页面上的信息。</p><p>在 “xpath &#x2F; css选择器 &#x2F; 正则表达式” 的解析模式中，这个工作正是人肉去完成的，人去解读这个页面，找到信息所在元素。而在 “data highlighter” 的解析模式中，也需要人在多个页面中进行标注，告诉机器每个属性所在。</p><p>但是作为计算机，是否能做到这一点？micro-data 通过开放的格式约定，通过 <code>property</code> 这一个特殊的属性标记告诉计算机一个元素说的是什么。而模板挖掘通过：xpath，元素class，id属性，上下文等特征去挖掘元素的含义。</p><p>但是，页面样式结构，在人类在没有足够的知识情况下，也有可能会无法解读，例如我们的爷爷奶奶可能就看不懂网页上说的是什么。同时，正如语言是有二义性的一样，页面结构也会如此，这给计算机去理解，页面说的是什么，带来了巨大的困难。</p><h3 id="这个元素和其他的元素有什么区别"><a href="#这个元素和其他的元素有什么区别" class="headerlink" title="这个元素和其他的元素有什么区别"></a>这个元素和其他的元素有什么区别</h3><p>因为，大批量数据抽取是计算机的活，这需要 <strong>准确</strong> 地告诉计算机，你想要抽取的元素是哪一个。在 “xpath &#x2F; css选择器 &#x2F; 正则表达式” 的解析模式中，xpath、css选择器、正则表达式正是对这一信息的描述。选取一个正确的表达式，即涵盖不同页面，又和其他属性有所区分，是一件需要经验和技巧的工作。而 “data highlighter” 将这个工作交给了计算机。“模板生成和套用” 过程中也由计算机分析出了规则。</p><p>而对于 “micro-data” 来说，这个问题有些特殊。通过开放的标准格式，程序已经能够了解每个元素在说什么了，那么定位就不再有意义。但是反过来，这又何尝不是一种定位。</p><h3 id="结构化解析"><a href="#结构化解析" class="headerlink" title="结构化解析"></a>结构化解析</h3><p>结构化解析实质是计算机对一个页面的理解，无论这种理解是人去创建规则、做出某种约定 还是 机器学习。上面列举的四种解析方式，“xpath &#x2F; css选择器 &#x2F; 正则表达式” 和 “data highlighter” 回答了这个元素和其他的有什么区别。 “micro-data” 利用了一个元素在说什么。而 “模板生成与提取” 同时涉及元素说什么，它在哪。</p><p>那么作为结构化解析的究级形态是怎样？我们可以假想一个人，他打开一个页面就能知道上面说的是什么，有什么样的信息，这是人类对于：通过网页获取知识的一种能力，一种方式。计算机也是一样，结构化抽取 就是 计算机从网页中获取知识的过程。“这个元素和其他的元素有什么区别” 终究只是在无法达到：计算机理解 <strong>一个页面在说什么</strong> 的辅助手段。理解 “一个元素在说什么” 乃至 “一个页面在说什么” 我认为是才是其究级形态，而结构化数据也不过是计算机，对于浩瀚互联网信息理解的一种表达罢了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;已经五个月没有更新 blog 了，这五个月全身心投入到了两个关于如何从页面上抽取结构化数据的项目上。这也是我加入某厂最主要的原因。其中一个全自动模板生成抽取器，虽然还不完全能够实用，但比1年前效果好太多，同时也让我想明白了一些问题。这都是下文主要讨论的问题。&lt;/p&gt;
&lt;p&gt;</summary>
      
    
    
    
    
    <category term="html" scheme="https://binux.blog/tags/html/"/>
    
    <category term="infomation-extraction" scheme="https://binux.blog/tags/infomation-extraction/"/>
    
    <category term="wrapper-genaration" scheme="https://binux.blog/tags/wrapper-genaration/"/>
    
    <category term="xpath" scheme="https://binux.blog/tags/xpath/"/>
    
    <category term="css-selector" scheme="https://binux.blog/tags/css-selector/"/>
    
  </entry>
  
  <entry>
    <title>pyspider架构设计</title>
    <link href="https://binux.blog/2014/02/pyspider-architecture/"/>
    <id>https://binux.blog/2014/02/pyspider-architecture/</id>
    <published>2014-02-28T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<h1 id="前言"><a href="#前言" class="headerlink" title="前言"></a>前言</h1><p><a href="https://github.com/binux/pyspider">pyspider</a>是我一年多之前做的一个爬虫架构的开源化实现。主要的功能需求是：</p><ul><li>抓取、更新调度多站点的特定的页面</li><li>需要对页面进行结构化信息提取</li><li>灵活可扩展，稳定可监控</li></ul><p>而这也是绝大多数python爬虫的需求 —— 定向抓取，结构化化解析。但是面对结构迥异的各种网站，单一的抓取模式并不一定能满足，灵活的抓取控制是必须的。为了达到这个目的，单纯的配置文件往往不够灵活，于是，通过脚本去控制抓取是我最后的选择。<br>而去重调度，队列，抓取，异常处理，监控等功能作为框架，提供给抓取脚本，并保证灵活性。最后加上web的编辑调试环境，以及web任务监控，即成为了这套框架。</p><p>pyspider的设计基础是：<strong>以python脚本驱动的抓取环模型爬虫</strong></p><ul><li>通过python脚本进行结构化信息的提取，follow链接调度抓取控制，实现最大的灵活性</li><li>通过web化的脚本编写、调试环境。web展现调度状态</li><li>抓取环模型成熟稳定，模块间相互独立，通过消息队列连接，从单进程到多机分布式灵活拓展</li></ul><p><del>这与后来在某厂看到的spider系统整体架构上区别不大</del></p><p><img src="/assets/image/pyspider.png" alt="pyspider"></p><h1 id="功能"><a href="#功能" class="headerlink" title="功能"></a>功能</h1><p><strong>webui</strong></p><ul><li>web的可视化任务监控</li><li>web脚本编写，单步调试</li><li>异常捕获、log捕获，print捕获等</li></ul><p>scheduler</p><ul><li>任务优先级</li><li>周期定时任务</li><li>流量控制</li><li>基于时间周期 或 前链标签（例如更新时间）的重抓取调度</li></ul><p>fetcher</p><ul><li>dataurl支持，用于假抓取模拟传递</li><li>method, header, cookie, proxy, etag, last_modified, timeout 等等抓取调度控制</li><li><em>可以通过适配类似 <a href="http://phantomjs.org/">phantomjs</a> 的webkit引擎支持渲染</em></li></ul><p>processor</p><ul><li>内置的pyquery，以jQuery解析页面</li><li>在脚本中完全控制调度抓取的各项参数</li><li>可以向后链传递信息</li><li>异常捕获</li></ul><h1 id="架构"><a href="#架构" class="headerlink" title="架构"></a>架构</h1><p>pyspider的架构主要分为 scheduler（调度器）, fetcher（抓取器）, processor（脚本执行）：</p><p><img src="/assets/image/pyspider-arch.png" alt="pyspider-arch"></p><ul><li><p>各个组件间使用消息队列连接，除了scheduler是单点的，fetcher 和 processor 都是可以多实例分布式部署的。 scheduler 负责整体的调度控制</p></li><li><p>任务由 scheduler 发起调度，fetcher 抓取网页内容， processor 执行预先编写的python脚本，输出结果或产生新的提链任务（发往 scheduler），形成闭环。</p></li><li><p>每个脚本可以灵活使用各种python库对页面进行解析，使用框架API控制下一步抓取动作，通过设置回调控制解析动作。</p></li></ul><p><em><strong>注：output部分设计尚未决定，因为希望输出也可以很灵活地进行。现在是在脚本中有一个<code>on_result</code>的回调，在里面可以自行实现结果输出。</strong></em></p>]]></content>
    
    
    <summary type="html">a spider system in python on web</summary>
    
    
    
    
    <category term="python" scheme="https://binux.blog/tags/python/"/>
    
    <category term="spider" scheme="https://binux.blog/tags/spider/"/>
    
    <category term="opensource" scheme="https://binux.blog/tags/opensource/"/>
    
  </entry>
  
  <entry>
    <title>基于封禁IP名单的自动路由</title>
    <link href="https://binux.blog/2014/01/add-blocked-ip-to-route/"/>
    <id>https://binux.blog/2014/01/add-blocked-ip-to-route/</id>
    <published>2014-01-27T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>年末本来很闲的，一个月把标日初级上看完了；结果前天开始被拉去做一个要求年后第一周上线的的项目。。还是本来是一个部门做的那种。。于是本月的blog只好凑字数了。。</p><p><i>翻<del>自动</i>墙</del>路由基本除去apnic的国内ipv4白名单走国内方案，就剩下autoddvpn的封禁ip列表了（透明代理不考虑）。国内ip白名单的问题是，如果要玩外服DOTA，还得手动加上各种游戏的服务器IP，而autoddvpn万年不更新，很多时候根本命中不了。</p><p>于是，有了下面这个根据DNS查询记录添加封禁IP记录的方法：</p><ul><li>Linux环境</li><li>有VPN</li><li>通过dnsmasq查询DNS，并打开日志</li><li>通过匹配gfwlist的域名判断对应ip是否被封禁，然后添加到路由表中</li></ul><p>通过脚本</p><script src="https://gist.github.com/binux/8456129.js"></script><p><code>logread -f</code> 可以替换为 <code>tail -f 日志文件</code><br><code>dev pptp-vpn</code> 可以替换为建立VPN的链接的名字</p><p>不过，缺陷是。。第一次访问时需要过1分钟左右才能生效。。</p><p>另外，这个是福利： <a href="http://f.binux.me/lifandb.html">lifandb.html</a> 来自 <a href="https://github.com/youxiachai/lifandb/">github&#x2F;youxiachai&#x2F;lifandb</a> （请用chrome打开，如果安装了adblock-plus请先禁用）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;年末本来很闲的，一个月把标日初级上看完了；结果前天开始被拉去做一个要求年后第一周上线的的项目。。还是本来是一个部门做的那种。。于是本月的blog只好凑字数了。。&lt;/p&gt;
&lt;p&gt;&lt;i&gt;翻&lt;del&gt;自动&lt;/i&gt;墙&lt;/del&gt;路由基本除去apnic的国内ipv4白名单走国内方案，</summary>
      
    
    
    
    
    <category term="vpn" scheme="https://binux.blog/tags/vpn/"/>
    
    <category term="route" scheme="https://binux.blog/tags/route/"/>
    
  </entry>
  
  <entry>
    <title>足兆叉虫的2013</title>
    <link href="https://binux.blog/2013/12/2013/"/>
    <id>https://binux.blog/2013/12/2013/</id>
    <published>2013-12-29T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>我是从来不记日子的，这导致我也不知道有些事情是2013年发生的，还是2012年发生的，亦或只是我的臆想。即便如此，2013年也是变化的一年。</p><p>跳槽，工资没涨，工作忙了2倍，但经手了更大的系统（虽然设计很渣），更多协调，带小弟，基本达到了初衷，也说不上是好是坏。搬离大学生活圈、一个人住，第一次有家的感觉，虽然依旧一个人。</p><p>想学日语，想出国，但完全没有干劲。</p><p>依旧是没有理想，没有希望的一年，就这样一觉不起就好了。</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;我是从来不记日子的，这导致我也不知道有些事情是2013年发生的，还是2012年发生的，亦或只是我的臆想。即便如此，2013年也是变化的一年。&lt;/p&gt;
&lt;p&gt;跳槽，工资没涨，工作忙了2倍，但经手了更大的系统（虽然设计很渣），更多协调，带小弟，基本达到了初衷，也说不上是好是坏。</summary>
      
    
    
    
    
    <category term="2013" scheme="https://binux.blog/tags/2013/"/>
    
  </entry>
  
  <entry>
    <title>用FTP的方式访问迅雷离线</title>
    <link href="https://binux.blog/2013/11/xunlei-lixian-ftp-proxy/"/>
    <id>https://binux.blog/2013/11/xunlei-lixian-ftp-proxy/</id>
    <published>2013-11-17T08:00:00.000Z</published>
    <updated>2022-08-27T19:30:55.683Z</updated>
    
    <content type="html"><![CDATA[<p>这只是一个demo，用于尝试将http协议转换成FTP，通过FTP方式访问类似网盘这样的空间（毕竟他们的原语都是文件夹）。使用 tornado ioloop 实现完全异步，在 tornado 的 iostream 之上手写了一个ftp服务器。</p><p><strong>如果你想要快速使用：</strong></p><p>ftp方式访问迅雷：<br><code>python -c &quot;u=&#39;http://f.binux.me/pyproxy.zip&#39;;import urllib2,sys,tempfile;f=tempfile.NamedTemporaryFile(suffix=&#39;.zip&#39;);urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler()));f.write(urllib2.urlopen(u).read());sys.path.insert(0,f.name);f.flush();from xunlei_ftpserver import run;run();&quot;</code></p><p>http串流离线内容<br><code>python -c &quot;u=&#39;http://f.binux.me/pyproxy.zip&#39;;import urllib2,sys,tempfile;f=tempfile.NamedTemporaryFile(suffix=&#39;.zip&#39;);urllib2.install_opener(urllib2.build_opener(urllib2.ProxyHandler()));f.write(urllib2.urlopen(u).read());sys.path.insert(0,f.name);f.flush();from xunlei_webserver import run;run();&quot;</code></p><p>另外还有一个使用代理api方式直接共享离线空间的例子：<br><a href="http://jsbin.com/uQinidA/2/quiet">http://jsbin.com/uQinidA/2/quiet</a></p><p>github地址：<a href="https://github.com/binux/xunlei-lixian-proxy">https://github.com/binux/xunlei-lixian-proxy</a></p><p>中文简介</p><ul><li>通过ftp的方式访问你的迅雷离线空间</li><li>在线串流离线空间中的视频到任何播放器</li><li>完全异步化(使用tornado ioloop)</li><li>这只是一个多协议转换的原理验证演示，不保证可以用于生产环境</li></ul><hr /><p>用了几天，发现tornado的iostream其实问题还是蛮多的，比如当上下游速度不一致的时候，会有大量的数据堵在上游的 read buffer 或者 下游的 write buffer 上。因为tornado是定位于web服务器的，单个请求大都不大，但是在代理文件的时候 buffer 就会占用大量的内存。代码里面有尝试修复，但是效果不理想，在小内存的 Linux 盒子上经常因为爆内存被 kill。</p><p>写了这个东西，感觉完全异步不总是好的，ftp作为有状态的协议，请求以及返回的顺序很重要，异步了之后这样的顺序就很难控制（比如客户端紧接着RETR发送了一个PWD，必须先响应完RETR才能响应PWD，但是由于是异步的，实际有可能PWD先返回了，这需要双方至少有一方严格按照顺序处理）</p>]]></content>
    
    
      
      
    <summary type="html">&lt;p&gt;这只是一个demo，用于尝试将http协议转换成FTP，通过FTP方式访问类似网盘这样的空间（毕竟他们的原语都是文件夹）。使用 tornado ioloop 实现完全异步，在 tornado 的 iostream 之上手写了一个ftp服务器。&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;</summary>
      
    
    
    
    
    <category term="lixian" scheme="https://binux.blog/tags/lixian/"/>
    
    <category term="xunlei" scheme="https://binux.blog/tags/xunlei/"/>
    
    <category term="ftpserver" scheme="https://binux.blog/tags/ftpserver/"/>
    
    <category term="webserver" scheme="https://binux.blog/tags/webserver/"/>
    
    <category term="tornado" scheme="https://binux.blog/tags/tornado/"/>
    
    <category term="async" scheme="https://binux.blog/tags/async/"/>
    
  </entry>
  
</feed>
